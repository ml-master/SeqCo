(SeqCo) xiehong@amax:~/SeqCo$ sh seqco_scripts/train_cnndm.sh
tee: resutls/LE_sim_X,Y/cnndm_models/log.txt: No such file or directory
| distributed init (rank 2): tcp://localhost:14848
| distributed init (rank 3): tcp://localhost:14848
| distributed init (rank 1): tcp://localhost:14848
| distributed init (rank 0): tcp://localhost:14848
| initialized host amax as rank 2
| initialized host amax as rank 3
| initialized host amax as rank 1
| initialized host amax as rank 0
{   'accumulate_trans': None,
    'activation_dropout': 0.0,
    'activation_fn': 'gelu',
    'adam_betas': '(0.9, 0.999)',
    'adam_eps': 1e-08,
    'adaptive_input': False,
    'adaptive_softmax_cutoff': None,
    'adaptive_softmax_dropout': 0,
    'arch': 'backsum_transformer_bart_large',
    'article_downsampling': 'True',
    'attention_dropout': 0.1,
    'bart_mask_full_sent': 'False',
    'best_checkpoint_metric': 'loss',
    'bpe': None,
    'bt_beam_size': 1,
    'bucket_cap_mb': 25,
    'byol_ratio': '0',
    'change_langtok': False,
    'clip_norm': 0.1,
    'cpu': False,
    'criterion': 'label_smoothed_cross_entropy',
    'cross_byol': True,
    'cross_self_attention': False,
    'curriculum': 0,
    'data': 'data/cnn_dm-bin',
    'dataset_impl': None,
    'ddp_backend': 'no_c10d',
    'decoder_attention_heads': 16,
    'decoder_byol': '0',
    'decoder_embed_dim': 1024,
    'decoder_embed_path': None,
    'decoder_ffn_embed_dim': 4096,
    'decoder_input_dim': 1024,
    'decoder_layerdrop': 0,
    'decoder_layers': 12,
    'decoder_layers_to_keep': None,
    'decoder_learned_pos': True,
    'decoder_normalize_before': False,
    'decoder_output_dim': 1024,
    'device_id': 0,
    'disable_validation': False,
    'distributed_backend': 'nccl',
    'distributed_init_method': 'tcp://localhost:14848',
    'distributed_no_spawn': False,
    'distributed_port': -1,
    'distributed_rank': 0,
    'distributed_world_size': 4,
    'dropout': 0.1,
    'empty_cache_freq': 0,
    'encoder_attention_heads': 16,
    'encoder_embed_dim': 1024,
    'encoder_embed_path': None,
    'encoder_ffn_embed_dim': 4096,
    'encoder_layerdrop': 0,
    'encoder_layers': 12,
    'encoder_layers_to_keep': None,
    'encoder_learned_pos': True,
    'encoder_normalize_before': False,
    'end_learning_rate': 0.0,
    'fast_stat_sync': False,
    'find_unused_parameters': True,
    'fix_batches_to_gpus': False,
    'fixed_validation_seed': None,
    'force_anneal': None,
    'fp16': True,
    'fp16_init_scale': 128,
    'fp16_scale_tolerance': 0.0,
    'fp16_scale_window': None,
    'gen_sum_len': 140,
    'gold_gen_byol': '1',
    'init_from_pretrained_doc_model': True,
    'insert_sep': 'False',
    'keep_interval_updates': -1,
    'keep_last_epochs': -1,
    'label_smoothing': 0.1,
    'lambda_bart_pretrain_config': '0.0',
    'lambda_denoising_config': '0',
    'lambda_otf_bt_config': '0',
    'lambda_parallel_config': '1',
    'layer_wise_attention': False,
    'layernorm_embedding': True,
    'lazy_load': False,
    'left_pad_source': 'True',
    'left_pad_target': 'False',
    'load_decoders': True,
    'log_format': None,
    'log_interval': 50,
    'lr': [4e-05],
    'lr_scheduler': 'polynomial_decay',
    'max_epoch': 0,
    'max_sentences': 1,
    'max_sentences_valid': 1,
    'max_source_positions': 1024,
    'max_target_positions': 1024,
    'max_tokens': None,
    'max_tokens_valid': None,
    'max_update': 0,
    'max_word_shuffle_distance': 3.0,
    'maximize_best_checkpoint_metric': False,
    'memory_efficient_fp16': True,
    'min_loss_scale': 0.0001,
    'min_lr': -1,
    'momentum_contrast_beta': '0.99',
    'momentum_contrast_capcity': 10000,
    'momentum_contrast_loss_ratio': '0',
    'momentum_contrast_t': 1,
    'no_cross_attention': False,
    'no_epoch_checkpoints': True,
    'no_last_checkpoints': False,
    'no_progress_bar': False,
    'no_save': False,
    'no_save_optimizer_state': False,
    'no_scale_embedding': True,
    'no_token_positional_embeddings': False,
    'num_workers': 0,
    'optimizer': 'adam',
    'optimizer_overrides': '{}',
    'parallel_byol_ratio': '0',
    'pg_ratio': '0',
    'pooler_activation_fn': 'tanh',
    'pooler_dropout': 0.0,
    'power': 1.0,
    'pretrained_doc_model_path': '/data/xiehong/SeqCo/cnndm_bart/bart.large/model.pt',
    'raw_text': False,
    'relu_dropout': 0.0,
    'required_batch_size_multiple': 1,
    'reset_dataloader': False,
    'reset_lr_scheduler': False,
    'reset_meters': False,
    'reset_optimizer': False,
    'restore_file': 'checkpoint_last.pt',
    'save_dir': 'resutls/LE_sim_X,Y/cnndm_models/',
    'save_interval': 1,
    'save_interval_updates': 0,
    'seed': 1,
    'sentence_avg': False,
    'share_all_embeddings': True,
    'share_decoder_embeddings': False,
    'share_decoder_input_output_embed': True,
    'share_decoders': False,
    'share_encoder_embeddings': False,
    'share_encoders': True,
    'skip_invalid_size_inputs_valid_test': True,
    'source_lang': 'article',
    'summary_upsampling': 'True',
    'symmetrical': True,
    'target_lang': 'summary',
    'task': 'finetune_summarization',
    'tensorboard_logdir': '',
    'threshold_loss_scale': None,
    'tokenizer': None,
    'total_num_update': 40000,
    'train_subset': 'train',
    'truncate_source_positions': 1024,
    'two_side': False,
    'update_freq': [4],
    'upsample_primary': 1,
    'use_bmuf': False,
    'user_dir': None,
    'valid_subset': 'valid',
    'validate_interval': 1,
    'warmup_updates': 2000,
    'weight_decay': 0.01,
    'word_blanking_prob': 0.2,
    'word_dropout_prob': 0.1}
| [Dictionary] : 50265 types
add [article_bos] to dict
add [summary_bos] to dict
add <sep> to dict
| loaded 239 examples from: data/cnn_dm-bin/valid.article-summary.article
| loaded 239 examples from: data/cnn_dm-bin/valid.article-summary.summary
| parallel-data/cnn_dm-bin valid 239 examples
BacksumTransformerModel(
  (models): ModuleDict(
    (article-summary): FairseqEncoderDecoderModel(
      (encoder): TransformerEncoder(
        (embed_tokens): Embedding(50265, 1024, padding_idx=1)
        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (decoder): TransformerDecoder(
        (embed_tokens): Embedding(50265, 1024, padding_idx=1)
        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
        (layers): ModuleList(
          (0): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): MultiheadAttention(
              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (encoder_extra_fc): Sequential(
    (0): Linear(in_features=1024, out_features=4096, bias=True)
    (1): ReLU()
    (2): Linear(in_features=4096, out_features=1024, bias=True)
  )
  (momentum_encoder): TransformerEncoder(
    (embed_tokens): Embedding(50265, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (momentum_encoder_extra_fc): Sequential(
    (0): Linear(in_features=1024, out_features=4096, bias=True)
    (1): ReLU()
    (2): Linear(in_features=4096, out_features=1024, bias=True)
  )
  (cross_attention): MultiheadAttention(
    (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
  )
)
| model backsum_transformer_bart_large, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 630956032 (num. trained: 418883584)
| training on 4 GPUs
| max tokens per GPU = None and max sentences per GPU = 1
Load 370 parameters
Reserve 370 parameters
| loaded checkpoint /data/xiehong/SeqCo/cnndm_bart/bart.large/model.pt (epoch 41 @ 0 updates)
| WARNING: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
| loading train data for epoch 0
| loaded 5499 examples from: data/cnn_dm-bin/train.article-summary.article
| loaded 5499 examples from: data/cnn_dm-bin/train.article-summary.summary
| parallel-data/cnn_dm-bin train 5499 examples
| loaded 5499 examples from: data/cnn_dm-bin/train.article-summary.article
| loaded 5499 examples from: data/cnn_dm-bin/train.article-summary.summary
| backtranslate-article: data/cnn_dm-bin train 5499 examples
| WARNING: overflow detected, setting loss scale to: 64.0
| WARNING: overflow detected, setting loss scale to: 32.0
| WARNING: overflow detected, setting loss scale to: 16.0
| WARNING: overflow detected, setting loss scale to: 8.0
| WARNING: overflow detected, setting loss scale to: 4.0
| WARNING: overflow detected, setting loss scale to: 2.0
| WARNING: overflow detected, setting loss scale to: 1.0
| WARNING: overflow detected, setting loss scale to: 0.5
| WARNING: overflow detected, setting loss scale to: 0.25
| WARNING: overflow detected, setting loss scale to: 0.125
| epoch 001:     50 / 344 loss=11.143, nll_loss=7.900, ppl=238.86, wps=1865, ups=0, wpb=13936.098, bsz=48.000, num_updates=41, lr=8.2e-07, gnorm=233.875, clip=1.000, oom=0.000, loss_scale=0.125, wall=306, train_wall=1.07265e+06, article-summar      y:loss=9.74795, article-summary:nll_loss=7.89414, article-summary:ntokens=4629.85, article-summary:nsentences=16, article-summary:sample_size=4629.85, gold_gen_byol:article:loss=1.39474, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9306.24, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| WARNING: overflow detected, setting loss scale to: 0.0625
| epoch 001:    100 / 344 loss=10.108, nll_loss=6.666, ppl=101.55, wps=2146, ups=0, wpb=14359.800, bsz=48.000, num_updates=90, lr=1.8e-06, gnorm=190.750, clip=1.000, oom=0.000, loss_scale=0.062, wall=602, train_wall=1.07295e+06, article-summar      y:loss=8.71416, article-summary:nll_loss=6.66705, article-summary:ntokens=4768.29, article-summary:nsentences=16, article-summary:sample_size=4768.29, gold_gen_byol:article:loss=1.39394, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9591.51, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 001:    150 / 344 loss=8.967, nll_loss=5.441, ppl=43.44, wps=2251, ups=0, wpb=14335.436, bsz=48.000, num_updates=140, lr=2.8e-06, gnorm=133.125, clip=1.000, oom=0.000, loss_scale=0.062, wall=892, train_wall=1.07324e+06, article-summary      :loss=7.57985, article-summary:nll_loss=5.42879, article-summary:ntokens=4773.78, article-summary:nsentences=16, article-summary:sample_size=4773.78, gold_gen_byol:article:loss=1.38734, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9561.66, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 001:    200 / 344 loss=8.104, nll_loss=4.669, ppl=25.43, wps=2299, ups=0, wpb=14370.426, bsz=48.000, num_updates=190, lr=3.8e-06, gnorm=100.062, clip=1.000, oom=0.000, loss_scale=0.062, wall=1188, train_wall=1.07354e+06, article-summar      y:loss=6.78021, article-summary:nll_loss=4.65961, article-summary:ntokens=4783.37, article-summary:nsentences=16, article-summary:sample_size=4783.37, gold_gen_byol:article:loss=1.32348, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9587.05, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| WARNING: overflow detected, setting loss scale to: 0.03125
| epoch 001:    250 / 344 loss=7.472, nll_loss=4.166, ppl=17.95, wps=2302, ups=0, wpb=14219.925, bsz=48.000, num_updates=239, lr=4.78e-06, gnorm=80.750, clip=1.000, oom=0.000, loss_scale=0.031, wall=1476, train_wall=1.07382e+06, article-summar      y:loss=6.25328, article-summary:nll_loss=4.16025, article-summary:ntokens=4728.14, article-summary:nsentences=16, article-summary:sample_size=4728.14, gold_gen_byol:article:loss=1.21918, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9491.78, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 001:    300 / 344 loss=6.981, nll_loss=3.809, ppl=14.01, wps=2313, ups=0, wpb=14135.415, bsz=48.000, num_updates=289, lr=5.78e-06, gnorm=66.812, clip=1.000, oom=0.000, loss_scale=0.031, wall=1766, train_wall=1.07411e+06, article-summar      y:loss=5.8689, article-summary:nll_loss=3.80047, article-summary:ntokens=4708.87, article-summary:nsentences=16, article-summary:sample_size=4708.87, gold_gen_byol:article:loss=1.11228, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9426.55, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 001 | loss 6.657 | nll_loss 3.577 | ppl 11.93 | wps 2322 | ups 0 | wpb 14084.401 | bsz 47.889 | num_updates 332 | lr 6.64e-06 | gnorm 58.219 | clip 1.000 | oom 0.000 | loss_scale 0.031 | wall 2014 | train_wall 1.07436e+06 | article-sum      mary:loss 5.62364 | article-summary:nll_loss 3.57186 | article-summary:ntokens 4685.65 | article-summary:nsentences 15.9849 | article-summary:sample_size 4685.65 | gold_gen_byol:article:loss 1.0346 | gold_gen_byol:article:nll_loss 0 | gold_gen      _byol:article:ntokens 9427.14 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 001 | valid on 'valid' subset | loss 3.832 | nll_loss 1.837 | ppl 3.57 | num_updates 332 | article-summary:loss 3.78706 | article-summary:nll_loss 1.78651 | article-summary:ntokens 1140.18 | article-summary:nsentences 3.98333 | article      -summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 1 @ 332 updates) (writing took 7.734256267547607 seconds)
| epoch 002:     50 / 344 loss=4.262, nll_loss=1.906, ppl=3.75, wps=3012, ups=0, wpb=13882.745, bsz=48.000, num_updates=383, lr=7.66e-06, gnorm=5.695, clip=1.000, oom=0.000, loss_scale=0.031, wall=2263, train_wall=1.0746e+06, gold_gen_byol:art      icle:loss=0.418529, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9249.41, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.84352, article-summary:nll_loss=1.91035, article-sum      mary:ntokens=4633.33, article-summary:nsentences=16, article-summary:sample_size=4633.33
| epoch 002:    100 / 344 loss=4.179, nll_loss=1.847, ppl=3.6, wps=3047, ups=0, wpb=14052.802, bsz=48.000, num_updates=433, lr=8.66e-06, gnorm=3.949, clip=1.000, oom=0.000, loss_scale=0.031, wall=2494, train_wall=1.07483e+06, gold_gen_byol:art      icle:loss=0.397745, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9389.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.78085, article-summary:nll_loss=1.84876, article-sum      mary:ntokens=4662.86, article-summary:nsentences=16, article-summary:sample_size=4662.86
| epoch 002:    150 / 344 loss=4.136, nll_loss=1.823, ppl=3.54, wps=3072, ups=0, wpb=14158.815, bsz=48.000, num_updates=483, lr=9.66e-06, gnorm=3.363, clip=1.000, oom=0.000, loss_scale=0.031, wall=2724, train_wall=1.07506e+06, gold_gen_byol:ar      ticle:loss=0.381526, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9464.66, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.75456, article-summary:nll_loss=1.825, article-summ      ary:ntokens=4694.15, article-summary:nsentences=16, article-summary:sample_size=4694.15
| epoch 002:    200 / 344 loss=4.120, nll_loss=1.823, ppl=3.54, wps=3063, ups=0, wpb=14137.174, bsz=48.000, num_updates=533, lr=1.066e-05, gnorm=3.076, clip=1.000, oom=0.000, loss_scale=0.031, wall=2956, train_wall=1.07529e+06, gold_gen_byol:a      rticle:loss=0.36861, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9463.14, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.75132, article-summary:nll_loss=1.82547, article-su      mmary:ntokens=4674.03, article-summary:nsentences=16, article-summary:sample_size=4674.03
| epoch 002:    250 / 344 loss=4.077, nll_loss=1.791, ppl=3.46, wps=3070, ups=0, wpb=14228.215, bsz=48.000, num_updates=583, lr=1.166e-05, gnorm=2.873, clip=1.000, oom=0.000, loss_scale=0.031, wall=3192, train_wall=1.07552e+06, gold_gen_byol:a      rticle:loss=0.357655, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9535.78, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.71915, article-summary:nll_loss=1.79397, article-s      ummary:ntokens=4692.44, article-summary:nsentences=16, article-summary:sample_size=4692.44
| epoch 002:    300 / 344 loss=4.051, nll_loss=1.776, ppl=3.43, wps=3072, ups=0, wpb=14175.173, bsz=48.000, num_updates=633, lr=1.266e-05, gnorm=2.861, clip=1.000, oom=0.000, loss_scale=0.031, wall=3417, train_wall=1.07575e+06, gold_gen_byol:a      rticle:loss=0.348854, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9495.06, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.70175, article-summary:nll_loss=1.77793, article-s      ummary:ntokens=4680.12, article-summary:nsentences=16, article-summary:sample_size=4680.12
| epoch 002 | loss 4.040 | nll_loss 1.774 | ppl 3.42 | wps 3074 | ups 0 | wpb 14156.073 | bsz 47.985 | num_updates 676 | lr 1.352e-05 | gnorm 2.738 | clip 1.000 | oom 0.000 | loss_scale 0.031 | wall 3613 | train_wall 1.07594e+06 | gold_gen_byo      l:article:loss 0.342241 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9477.07 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 3.6977 | article-summary:nll_loss 1.77608 |       article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 002 | valid on 'valid' subset | loss 3.577 | nll_loss 1.635 | ppl 3.11 | num_updates 676 | best_loss 3.57655 | article-summary:loss 3.53776 | article-summary:nll_loss 1.59262 | article-summary:ntokens 1140.18 | article-summary:nsentenc      es 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 2 @ 676 updates) (writing took 14.016321659088135 seconds)
| epoch 003:     50 / 344 loss=3.866, nll_loss=1.663, ppl=3.17, wps=3069, ups=0, wpb=14437.255, bsz=48.000, num_updates=727, lr=1.454e-05, gnorm=14.516, clip=1.000, oom=0.000, loss_scale=0.031, wall=3873, train_wall=1.07618e+06, article-summar      y:loss=3.57786, article-summary:nll_loss=1.66285, article-summary:ntokens=4794.27, article-summary:nsentences=16, article-summary:sample_size=4794.27, gold_gen_byol:article:loss=0.287931, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9642.98, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 003:    100 / 344 loss=3.860, nll_loss=1.659, ppl=3.16, wps=3102, ups=0, wpb=14535.149, bsz=48.000, num_updates=777, lr=1.554e-05, gnorm=8.656, clip=1.000, oom=0.000, loss_scale=0.031, wall=4106, train_wall=1.07642e+06, article-summary      :loss=3.57458, article-summary:nll_loss=1.66151, article-summary:ntokens=4811.23, article-summary:nsentences=16, article-summary:sample_size=4811.23, gold_gen_byol:article:loss=0.28534, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9723.92, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 003:    150 / 344 loss=3.832, nll_loss=1.635, ppl=3.11, wps=3095, ups=0, wpb=14439.907, bsz=48.000, num_updates=827, lr=1.654e-05, gnorm=6.391, clip=1.000, oom=0.000, loss_scale=0.031, wall=4337, train_wall=1.07665e+06, article-summary      :loss=3.5496, article-summary:nll_loss=1.63585, article-summary:ntokens=4777.34, article-summary:nsentences=16, article-summary:sample_size=4777.34, gold_gen_byol:article:loss=0.282444, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9662.57, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 003:    200 / 344 loss=3.821, nll_loss=1.628, ppl=3.09, wps=3106, ups=0, wpb=14436.975, bsz=48.000, num_updates=877, lr=1.754e-05, gnorm=5.406, clip=1.000, oom=0.000, loss_scale=0.031, wall=4567, train_wall=1.07688e+06, article-summary      :loss=3.54139, article-summary:nll_loss=1.62869, article-summary:ntokens=4775.94, article-summary:nsentences=16, article-summary:sample_size=4775.94, gold_gen_byol:article:loss=0.279374, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9661.03, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 003:    250 / 344 loss=3.817, nll_loss=1.627, ppl=3.09, wps=3075, ups=0, wpb=14195.410, bsz=48.000, num_updates=927, lr=1.854e-05, gnorm=4.742, clip=1.000, oom=0.000, loss_scale=0.031, wall=4792, train_wall=1.0771e+06, article-summary:      loss=3.54077, article-summary:nll_loss=1.62876, article-summary:ntokens=4706.77, article-summary:nsentences=16, article-summary:sample_size=4706.77, gold_gen_byol:article:loss=0.276439, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9488.64, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 003:    300 / 344 loss=3.803, nll_loss=1.618, ppl=3.07, wps=3063, ups=0, wpb=14088.007, bsz=48.000, num_updates=977, lr=1.954e-05, gnorm=4.281, clip=1.000, oom=0.000, loss_scale=0.031, wall=5017, train_wall=1.07733e+06, article-summary      :loss=3.52982, article-summary:nll_loss=1.61883, article-summary:ntokens=4675.71, article-summary:nsentences=16, article-summary:sample_size=4675.71, gold_gen_byol:article:loss=0.273358, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9412.29, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 003 | loss 3.795 | nll_loss 1.613 | ppl 3.06 | wps 3063 | ups 0 | wpb 14100.282 | bsz 47.985 | num_updates 1020 | lr 2.04e-05 | gnorm 3.971 | clip 1.000 | oom 0.000 | loss_scale 0.031 | wall 5216 | train_wall 1.07752e+06 | article-summ      ary:loss 3.52419 | article-summary:nll_loss 1.61419 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.270744 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol      :article:ntokens 9421.28 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 003 | valid on 'valid' subset | loss 3.471 | nll_loss 1.556 | ppl 2.94 | num_updates 1020 | best_loss 3.47058 | article-summary:loss 3.4342 | article-summary:nll_loss 1.51642 | article-summary:ntokens 1140.18 | article-summary:nsentenc      es 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 3 @ 1020 updates) (writing took 14.300835132598877 seconds)
| epoch 004:     50 / 344 loss=3.657, nll_loss=1.502, ppl=2.83, wps=3072, ups=0, wpb=14287.569, bsz=48.000, num_updates=1071, lr=2.142e-05, gnorm=1.865, clip=1.000, oom=0.000, loss_scale=0.031, wall=5475, train_wall=1.07776e+06, article-summar      y:loss=3.40955, article-summary:nll_loss=1.49861, article-summary:ntokens=4740.43, article-summary:nsentences=16, article-summary:sample_size=4740.43, gold_gen_byol:article:loss=0.247838, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9547.14, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 004:    100 / 344 loss=3.641, nll_loss=1.484, ppl=2.8, wps=3045, ups=0, wpb=14192.208, bsz=48.000, num_updates=1121, lr=2.242e-05, gnorm=1.791, clip=1.000, oom=0.000, loss_scale=0.031, wall=5708, train_wall=1.078e+06, article-summary:l      oss=3.39496, article-summary:nll_loss=1.48273, article-summary:ntokens=4707.77, article-summary:nsentences=16, article-summary:sample_size=4707.77, gold_gen_byol:article:loss=0.245696, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:nt      okens=9484.44, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 004:    150 / 344 loss=3.636, nll_loss=1.482, ppl=2.79, wps=3054, ups=0, wpb=14225.093, bsz=48.000, num_updates=1171, lr=2.342e-05, gnorm=1.771, clip=1.000, oom=0.000, loss_scale=0.031, wall=5941, train_wall=1.07823e+06, article-summar      y:loss=3.39232, article-summary:nll_loss=1.48172, article-summary:ntokens=4713.23, article-summary:nsentences=16, article-summary:sample_size=4713.23, gold_gen_byol:article:loss=0.243511, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9511.87, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 004:    200 / 344 loss=3.635, nll_loss=1.485, ppl=2.8, wps=3070, ups=0, wpb=14280.149, bsz=48.000, num_updates=1221, lr=2.442e-05, gnorm=1.766, clip=1.000, oom=0.000, loss_scale=0.031, wall=6172, train_wall=1.07846e+06, article-summary      :loss=3.39317, article-summary:nll_loss=1.48427, article-summary:ntokens=4729.32, article-summary:nsentences=16, article-summary:sample_size=4729.32, gold_gen_byol:article:loss=0.241356, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9550.83, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 004:    250 / 344 loss=3.631, nll_loss=1.484, ppl=2.8, wps=3062, ups=0, wpb=14212.777, bsz=48.000, num_updates=1271, lr=2.542e-05, gnorm=1.758, clip=1.000, oom=0.000, loss_scale=0.062, wall=6403, train_wall=1.07869e+06, article-summary      :loss=3.39122, article-summary:nll_loss=1.483, article-summary:ntokens=4711.31, article-summary:nsentences=16, article-summary:sample_size=4711.31, gold_gen_byol:article:loss=0.239409, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:nt      okens=9501.47, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 004:    300 / 344 loss=3.621, nll_loss=1.475, ppl=2.78, wps=3062, ups=0, wpb=14207.761, bsz=48.000, num_updates=1321, lr=2.642e-05, gnorm=1.739, clip=1.000, oom=0.000, loss_scale=0.062, wall=6634, train_wall=1.07892e+06, article-summar      y:loss=3.38328, article-summary:nll_loss=1.47521, article-summary:ntokens=4703.61, article-summary:nsentences=16, article-summary:sample_size=4703.61, gold_gen_byol:article:loss=0.237504, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9504.15, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 004 | loss 3.620 | nll_loss 1.477 | ppl 2.78 | wps 3047 | ups 0 | wpb 14107.084 | bsz 47.962 | num_updates 1364 | lr 2.728e-05 | gnorm 1.739 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 6830 | train_wall 1.07912e+06 | article-sum      mary:loss 3.38417 | article-summary:nll_loss 1.47699 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.236014 | gold_gen_byol:article:nll_loss 0 | gold_gen_byo      l:article:ntokens 9428.08 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 004 | valid on 'valid' subset | loss 3.410 | nll_loss 1.489 | ppl 2.81 | num_updates 1364 | best_loss 3.40995 | article-summary:loss 3.37368 | article-summary:nll_loss 1.45008 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 4 @ 1364 updates) (writing took 20.129042148590088 seconds)
| epoch 005:     50 / 344 loss=3.470, nll_loss=1.337, ppl=2.53, wps=2430, ups=0, wpb=14410.353, bsz=48.000, num_updates=1415, lr=2.83e-05, gnorm=1.633, clip=1.000, oom=0.000, loss_scale=0.062, wall=7159, train_wall=1.07942e+06, article-summary      :loss=3.25449, article-summary:nll_loss=1.33621, article-summary:ntokens=4743.06, article-summary:nsentences=16, article-summary:sample_size=4743.06, gold_gen_byol:article:loss=0.215662, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9667.29, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 005:    100 / 344 loss=3.447, nll_loss=1.321, ppl=2.5, wps=2391, ups=0, wpb=14232.950, bsz=48.000, num_updates=1465, lr=2.93e-05, gnorm=1.623, clip=1.000, oom=0.000, loss_scale=0.062, wall=7458, train_wall=1.07972e+06, article-summary:      loss=3.23706, article-summary:nll_loss=1.31976, article-summary:ntokens=4694.93, article-summary:nsentences=16, article-summary:sample_size=4694.93, gold_gen_byol:article:loss=0.210262, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9538.02, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 005:    150 / 344 loss=3.458, nll_loss=1.338, ppl=2.53, wps=2408, ups=0, wpb=14351.649, bsz=48.000, num_updates=1515, lr=3.03e-05, gnorm=1.664, clip=1.000, oom=0.000, loss_scale=0.062, wall=7757, train_wall=1.08002e+06, article-summary      :loss=3.25215, article-summary:nll_loss=1.33697, article-summary:ntokens=4739.3, article-summary:nsentences=16, article-summary:sample_size=4739.3, gold_gen_byol:article:loss=0.205654, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:nt      okens=9612.34, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 005:    200 / 344 loss=3.454, nll_loss=1.338, ppl=2.53, wps=2400, ups=0, wpb=14269.597, bsz=48.000, num_updates=1565, lr=3.13e-05, gnorm=1.680, clip=1.000, oom=0.000, loss_scale=0.062, wall=8052, train_wall=1.08031e+06, article-summary      :loss=3.25164, article-summary:nll_loss=1.33725, article-summary:ntokens=4721.82, article-summary:nsentences=16, article-summary:sample_size=4721.82, gold_gen_byol:article:loss=0.202122, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9547.78, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 005:    250 / 344 loss=3.463, nll_loss=1.353, ppl=2.55, wps=2390, ups=0, wpb=14209.351, bsz=48.000, num_updates=1615, lr=3.23e-05, gnorm=1.738, clip=1.000, oom=0.000, loss_scale=0.062, wall=8349, train_wall=1.08061e+06, article-summary      :loss=3.26423, article-summary:nll_loss=1.35204, article-summary:ntokens=4712.41, article-summary:nsentences=16, article-summary:sample_size=4712.41, gold_gen_byol:article:loss=0.19923, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9496.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 005:    300 / 344 loss=3.465, nll_loss=1.358, ppl=2.56, wps=2385, ups=0, wpb=14146.060, bsz=48.000, num_updates=1665, lr=3.33e-05, gnorm=1.725, clip=1.000, oom=0.000, loss_scale=0.062, wall=8642, train_wall=1.0809e+06, article-summary:      loss=3.26811, article-summary:nll_loss=1.35709, article-summary:ntokens=4695.95, article-summary:nsentences=16, article-summary:sample_size=4695.95, gold_gen_byol:article:loss=0.196886, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9450.11, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 005 | loss 3.459 | nll_loss 1.355 | ppl 2.56 | wps 2379 | ups 0 | wpb 14071.166 | bsz 47.892 | num_updates 1708 | lr 3.416e-05 | gnorm 1.717 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 8892 | train_wall 1.08115e+06 | article-sum      mary:loss 3.26443 | article-summary:nll_loss 1.35401 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.195193 | gold_gen_byol:article:nll_loss 0 | gold_gen_byo      l:article:ntokens 9419.55 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 005 | valid on 'valid' subset | loss 3.379 | nll_loss 1.486 | ppl 2.8 | num_updates 1708 | best_loss 3.37937 | article-summary:loss 3.34435 | article-summary:nll_loss 1.44773 | article-summary:ntokens 1140.18 | article-summary:nsentenc      es 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 5 @ 1708 updates) (writing took 13.977701425552368 seconds)
| epoch 006:     50 / 344 loss=3.336, nll_loss=1.226, ppl=2.34, wps=2979, ups=0, wpb=14004.216, bsz=48.000, num_updates=1759, lr=3.518e-05, gnorm=1.619, clip=1.000, oom=0.000, loss_scale=0.062, wall=9151, train_wall=1.08139e+06, gold_gen_byol:      article:loss=0.180793, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9360, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.15472, article-summary:nll_loss=1.23068, article-sum      mary:ntokens=4644.22, article-summary:nsentences=16, article-summary:sample_size=4644.22
| epoch 006:    100 / 344 loss=3.319, nll_loss=1.212, ppl=2.32, wps=3037, ups=0, wpb=14205.614, bsz=48.000, num_updates=1809, lr=3.618e-05, gnorm=1.606, clip=1.000, oom=0.000, loss_scale=0.062, wall=9384, train_wall=1.08162e+06, gold_gen_byol:      article:loss=0.180169, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9482.97, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.13892, article-summary:nll_loss=1.21602, article-      summary:ntokens=4722.64, article-summary:nsentences=16, article-summary:sample_size=4722.64
| epoch 006:    150 / 344 loss=3.320, nll_loss=1.217, ppl=2.33, wps=3012, ups=0, wpb=14128.576, bsz=48.000, num_updates=1859, lr=3.718e-05, gnorm=1.680, clip=1.000, oom=0.000, loss_scale=0.062, wall=9620, train_wall=1.08186e+06, gold_gen_byol:      article:loss=0.179448, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9437.46, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.14093, article-summary:nll_loss=1.21944, article-      summary:ntokens=4691.12, article-summary:nsentences=16, article-summary:sample_size=4691.12
| epoch 006:    200 / 344 loss=3.317, nll_loss=1.216, ppl=2.32, wps=3026, ups=0, wpb=14086.826, bsz=48.000, num_updates=1909, lr=3.818e-05, gnorm=1.678, clip=1.000, oom=0.000, loss_scale=0.062, wall=9847, train_wall=1.08208e+06, gold_gen_byol:      article:loss=0.178741, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9409.95, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.13821, article-summary:nll_loss=1.21726, article-      summary:ntokens=4676.88, article-summary:nsentences=16, article-summary:sample_size=4676.88
| epoch 006:    250 / 344 loss=3.319, nll_loss=1.220, ppl=2.33, wps=3037, ups=0, wpb=14141.402, bsz=48.000, num_updates=1959, lr=3.918e-05, gnorm=1.661, clip=1.000, oom=0.000, loss_scale=0.062, wall=10080, train_wall=1.08232e+06, gold_gen_byol      :article:loss=0.177984, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9445.23, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.14105, article-summary:nll_loss=1.22158, article      -summary:ntokens=4696.18, article-summary:nsentences=16, article-summary:sample_size=4696.18
| epoch 006:    300 / 344 loss=3.315, nll_loss=1.218, ppl=2.33, wps=3043, ups=0, wpb=14137.106, bsz=48.000, num_updates=2009, lr=3.99905e-05, gnorm=1.676, clip=1.000, oom=0.000, loss_scale=0.062, wall=10310, train_wall=1.08255e+06, gold_gen_by      ol:article:loss=0.177115, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9441.13, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=3.13836, article-summary:nll_loss=1.21991, artic      le-summary:ntokens=4695.98, article-summary:nsentences=16, article-summary:sample_size=4695.98
| epoch 006 | loss 3.319 | nll_loss 1.223 | ppl 2.34 | wps 3042 | ups 0 | wpb 14096.375 | bsz 47.985 | num_updates 2052 | lr 3.99453e-05 | gnorm 1.676 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 10506 | train_wall 1.08274e+06 | gold_gen      _byol:article:loss 0.176414 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9417.37 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 3.14301 | article-summary:nll_loss 1.225      85 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 006 | valid on 'valid' subset | loss 3.368 | nll_loss 1.489 | ppl 2.81 | num_updates 2052 | best_loss 3.36816 | article-summary:loss 3.33402 | article-summary:nll_loss 1.45158 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 6 @ 2052 updates) (writing took 12.898583173751831 seconds)
| epoch 007:     50 / 344 loss=3.161, nll_loss=1.056, ppl=2.08, wps=3062, ups=0, wpb=13922.882, bsz=48.000, num_updates=2103, lr=3.98916e-05, gnorm=1.549, clip=1.000, oom=0.000, loss_scale=0.062, wall=10757, train_wall=1.08297e+06, article-sum      mary:loss=2.99158, article-summary:nll_loss=1.05609, article-summary:ntokens=4619.51, article-summary:nsentences=16, article-summary:sample_size=4619.51, gold_gen_byol:article:loss=0.169763, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9303.37, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 007:    100 / 344 loss=3.158, nll_loss=1.053, ppl=2.08, wps=3077, ups=0, wpb=14074.960, bsz=48.000, num_updates=2153, lr=3.98389e-05, gnorm=1.699, clip=1.000, oom=0.000, loss_scale=0.062, wall=10987, train_wall=1.0832e+06, article-summ      ary:loss=2.98868, article-summary:nll_loss=1.05464, article-summary:ntokens=4671.12, article-summary:nsentences=16, article-summary:sample_size=4671.12, gold_gen_byol:article:loss=0.16918, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9403.84, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 007:    150 / 344 loss=3.168, nll_loss=1.068, ppl=2.1, wps=3057, ups=0, wpb=13956.921, bsz=48.000, num_updates=2203, lr=3.97863e-05, gnorm=1.755, clip=1.000, oom=0.000, loss_scale=0.062, wall=11214, train_wall=1.08343e+06, article-summ      ary:loss=2.99938, article-summary:nll_loss=1.0674, article-summary:ntokens=4619.09, article-summary:nsentences=16, article-summary:sample_size=4619.09, gold_gen_byol:article:loss=0.168584, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9337.83, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 007:    200 / 344 loss=3.174, nll_loss=1.075, ppl=2.11, wps=3069, ups=0, wpb=14075.647, bsz=48.000, num_updates=2253, lr=3.97337e-05, gnorm=1.734, clip=1.000, oom=0.000, loss_scale=0.062, wall=11447, train_wall=1.08366e+06, article-sum      mary:loss=3.00594, article-summary:nll_loss=1.07541, article-summary:ntokens=4654.47, article-summary:nsentences=16, article-summary:sample_size=4654.47, gold_gen_byol:article:loss=0.16808, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9421.17, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 007:    250 / 344 loss=3.169, nll_loss=1.070, ppl=2.1, wps=3054, ups=0, wpb=13957.633, bsz=48.000, num_updates=2303, lr=3.96811e-05, gnorm=1.696, clip=1.000, oom=0.000, loss_scale=0.125, wall=11672, train_wall=1.08389e+06, article-summ      ary:loss=3.00077, article-summary:nll_loss=1.07062, article-summary:ntokens=4630.8, article-summary:nsentences=16, article-summary:sample_size=4630.8, gold_gen_byol:article:loss=0.167777, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9326.84, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 007:    300 / 344 loss=3.179, nll_loss=1.083, ppl=2.12, wps=3065, ups=0, wpb=14038.395, bsz=48.000, num_updates=2353, lr=3.96284e-05, gnorm=1.688, clip=1.000, oom=0.000, loss_scale=0.125, wall=11904, train_wall=1.08412e+06, article-sum      mary:loss=3.01173, article-summary:nll_loss=1.08325, article-summary:ntokens=4656.63, article-summary:nsentences=16, article-summary:sample_size=4656.63, gold_gen_byol:article:loss=0.167234, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9381.77, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 007 | loss 3.179 | nll_loss 1.082 | ppl 2.12 | wps 3079 | ups 0 | wpb 14124.526 | bsz 47.985 | num_updates 2396 | lr 3.95832e-05 | gnorm 1.688 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 12103 | train_wall 1.08432e+06 | article-      summary:loss 3.01183 | article-summary:nll_loss 1.08374 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.166733 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9445.52 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 007 | valid on 'valid' subset | loss 3.356 | nll_loss 1.494 | ppl 2.82 | num_updates 2396 | best_loss 3.35637 | article-summary:loss 3.32486 | article-summary:nll_loss 1.45936 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_best.pt (epoch 7 @ 2396 updates) (writing took 13.353007555007935 seconds)
| WARNING: overflow detected, setting loss scale to: 0.0625
| epoch 008:     50 / 344 loss=3.034, nll_loss=0.924, ppl=1.9, wps=3074, ups=0, wpb=14501.080, bsz=48.000, num_updates=2446, lr=3.95305e-05, gnorm=1.710, clip=1.000, oom=0.000, loss_scale=0.062, wall=12359, train_wall=1.08456e+06, article-summ      ary:loss=2.87171, article-summary:nll_loss=0.924969, article-summary:ntokens=4812.36, article-summary:nsentences=16, article-summary:sample_size=4812.36, gold_gen_byol:article:loss=0.162546, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9688.72, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 008:    100 / 344 loss=3.038, nll_loss=0.930, ppl=1.91, wps=3062, ups=0, wpb=14257.380, bsz=48.000, num_updates=2496, lr=3.94779e-05, gnorm=1.634, clip=1.000, oom=0.000, loss_scale=0.062, wall=12589, train_wall=1.08478e+06, article-sum      mary:loss=2.87555, article-summary:nll_loss=0.93026, article-summary:ntokens=4719.9, article-summary:nsentences=16, article-summary:sample_size=4719.9, gold_gen_byol:article:loss=0.162074, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9537.48, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 008:    150 / 344 loss=3.042, nll_loss=0.937, ppl=1.91, wps=3048, ups=0, wpb=14053.507, bsz=48.000, num_updates=2546, lr=3.94253e-05, gnorm=1.611, clip=1.000, oom=0.000, loss_scale=0.062, wall=12815, train_wall=1.08501e+06, article-sum      mary:loss=2.88035, article-summary:nll_loss=0.936727, article-summary:ntokens=4657.72, article-summary:nsentences=16, article-summary:sample_size=4657.72, gold_gen_byol:article:loss=0.161857, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9395.79, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 008:    200 / 344 loss=3.039, nll_loss=0.935, ppl=1.91, wps=3067, ups=0, wpb=14118.450, bsz=48.000, num_updates=2596, lr=3.93726e-05, gnorm=1.645, clip=1.000, oom=0.000, loss_scale=0.062, wall=13044, train_wall=1.08524e+06, article-sum      mary:loss=2.87709, article-summary:nll_loss=0.934281, article-summary:ntokens=4675.35, article-summary:nsentences=16, article-summary:sample_size=4675.35, gold_gen_byol:article:loss=0.161589, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9443.1, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 008:    250 / 344 loss=3.045, nll_loss=0.942, ppl=1.92, wps=3058, ups=0, wpb=14079.984, bsz=48.000, num_updates=2646, lr=3.932e-05, gnorm=1.623, clip=1.000, oom=0.000, loss_scale=0.062, wall=13274, train_wall=1.08547e+06, article-summa      ry:loss=2.88349, article-summary:nll_loss=0.941837, article-summary:ntokens=4678.06, article-summary:nsentences=16, article-summary:sample_size=4678.06, gold_gen_byol:article:loss=0.161352, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9401.92, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 008:    300 / 344 loss=3.048, nll_loss=0.946, ppl=1.93, wps=3059, ups=0, wpb=14102.707, bsz=48.000, num_updates=2696, lr=3.92674e-05, gnorm=1.610, clip=1.000, oom=0.000, loss_scale=0.062, wall=13506, train_wall=1.0857e+06, article-summ      ary:loss=2.88639, article-summary:nll_loss=0.945771, article-summary:ntokens=4684.83, article-summary:nsentences=16, article-summary:sample_size=4684.83, gold_gen_byol:article:loss=0.161135, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9417.88, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 008 | loss 3.047 | nll_loss 0.947 | ppl 1.93 | wps 3056 | ups 0 | wpb 14090.866 | bsz 47.962 | num_updates 2739 | lr 3.92221e-05 | gnorm 1.600 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 13705 | train_wall 1.0859e+06 | article-s      ummary:loss 2.88627 | article-summary:nll_loss 0.946257 | article-summary:ntokens 4680.45 | article-summary:nsentences 15.9854 | article-summary:sample_size 4680.45 | gold_gen_byol:article:loss 0.161022 | gold_gen_byol:article:nll_loss 0 | gol      d_gen_byol:article:ntokens 9410.41 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 008 | valid on 'valid' subset | loss 3.377 | nll_loss 1.496 | ppl 2.82 | num_updates 2739 | best_loss 3.35637 | article-summary:loss 3.34521 | article-summary:nll_loss 1.46126 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 8 @ 2739 updates) (writing took 7.934513568878174 seconds)
| epoch 009:     50 / 344 loss=2.922, nll_loss=0.807, ppl=1.75, wps=2355, ups=0, wpb=13543.824, bsz=48.000, num_updates=2790, lr=3.91684e-05, gnorm=1.486, clip=1.000, oom=0.000, loss_scale=0.062, wall=14011, train_wall=1.08619e+06, article-sum      mary:loss=2.76224, article-summary:nll_loss=0.806159, article-summary:ntokens=4471.51, article-summary:nsentences=16, article-summary:sample_size=4471.51, gold_gen_byol:article:loss=0.160141, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9072.31, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 009:    100 / 344 loss=2.963, nll_loss=0.853, ppl=1.81, wps=2411, ups=0, wpb=14043.109, bsz=48.000, num_updates=2840, lr=3.91158e-05, gnorm=1.799, clip=1.000, oom=0.000, loss_scale=0.062, wall=14306, train_wall=1.08649e+06, article-sum      mary:loss=2.80326, article-summary:nll_loss=0.852285, article-summary:ntokens=4631.98, article-summary:nsentences=16, article-summary:sample_size=4631.98, gold_gen_byol:article:loss=0.160052, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9411.13, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 009:    150 / 344 loss=2.953, nll_loss=0.841, ppl=1.79, wps=2403, ups=0, wpb=13934.132, bsz=48.000, num_updates=2890, lr=3.90632e-05, gnorm=1.692, clip=1.000, oom=0.000, loss_scale=0.062, wall=14593, train_wall=1.08677e+06, article-sum      mary:loss=2.79275, article-summary:nll_loss=0.84124, article-summary:ntokens=4609.15, article-summary:nsentences=16, article-summary:sample_size=4609.15, gold_gen_byol:article:loss=0.15996, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9324.98, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 009:    200 / 344 loss=2.945, nll_loss=0.834, ppl=1.78, wps=2415, ups=0, wpb=13954.159, bsz=48.000, num_updates=2940, lr=3.90105e-05, gnorm=1.644, clip=1.000, oom=0.000, loss_scale=0.062, wall=14879, train_wall=1.08706e+06, article-sum      mary:loss=2.78488, article-summary:nll_loss=0.833918, article-summary:ntokens=4617.28, article-summary:nsentences=16, article-summary:sample_size=4617.28, gold_gen_byol:article:loss=0.159802, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9336.88, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 009:    250 / 344 loss=2.947, nll_loss=0.837, ppl=1.79, wps=2435, ups=0, wpb=14108.052, bsz=48.000, num_updates=2990, lr=3.89579e-05, gnorm=1.610, clip=1.000, oom=0.000, loss_scale=0.062, wall=15172, train_wall=1.08735e+06, article-sum      mary:loss=2.78719, article-summary:nll_loss=0.836661, article-summary:ntokens=4663.53, article-summary:nsentences=16, article-summary:sample_size=4663.53, gold_gen_byol:article:loss=0.159693, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9444.53, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 009:    300 / 344 loss=2.948, nll_loss=0.839, ppl=1.79, wps=2443, ups=0, wpb=14196.219, bsz=48.000, num_updates=3040, lr=3.89053e-05, gnorm=1.588, clip=1.000, oom=0.000, loss_scale=0.062, wall=15467, train_wall=1.08765e+06, article-sum      mary:loss=2.78874, article-summary:nll_loss=0.838803, article-summary:ntokens=4695.41, article-summary:nsentences=16, article-summary:sample_size=4695.41, gold_gen_byol:article:loss=0.15963, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9500.81, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 009 | loss 2.943 | nll_loss 0.834 | ppl 1.78 | wps 2433 | ups 0 | wpb 14111.631 | bsz 47.892 | num_updates 3083 | lr 3.886e-05 | gnorm 1.575 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 15713 | train_wall 1.08789e+06 | article-su      mmary:loss 2.78386 | article-summary:nll_loss 0.834109 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.159626 | gold_gen_byol:article:nll_loss 0 | gold_gen_b      yol:article:ntokens 9460.13 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 009 | valid on 'valid' subset | loss 3.397 | nll_loss 1.523 | ppl 2.87 | num_updates 3083 | best_loss 3.35637 | article-summary:loss 3.36792 | article-summary:nll_loss 1.49052 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 9 @ 3083 updates) (writing took 7.830454111099243 seconds)
| epoch 010:     50 / 344 loss=2.842, nll_loss=0.716, ppl=1.64, wps=3069, ups=0, wpb=14193.667, bsz=48.000, num_updates=3134, lr=3.88063e-05, gnorm=1.696, clip=1.000, oom=0.000, loss_scale=0.062, wall=15963, train_wall=1.08813e+06, gold_gen_by      ol:article:loss=0.159473, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9430.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.68219, article-summary:nll_loss=0.718085, arti      cle-summary:ntokens=4763.24, article-summary:nsentences=16, article-summary:sample_size=4763.24
| epoch 010:    100 / 344 loss=2.844, nll_loss=0.722, ppl=1.65, wps=3080, ups=0, wpb=14225.327, bsz=48.000, num_updates=3184, lr=3.87537e-05, gnorm=1.559, clip=1.000, oom=0.000, loss_scale=0.062, wall=16193, train_wall=1.08836e+06, gold_gen_by      ol:article:loss=0.159442, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9480.75, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.68506, article-summary:nll_loss=0.722653, arti      cle-summary:ntokens=4744.57, article-summary:nsentences=16, article-summary:sample_size=4744.57
| epoch 010:    150 / 344 loss=2.843, nll_loss=0.722, ppl=1.65, wps=3062, ups=0, wpb=14191.000, bsz=48.000, num_updates=3234, lr=3.87011e-05, gnorm=1.531, clip=1.000, oom=0.000, loss_scale=0.062, wall=16427, train_wall=1.08859e+06, gold_gen_by      ol:article:loss=0.159452, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9463.79, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.68387, article-summary:nll_loss=0.721746, arti      cle-summary:ntokens=4727.21, article-summary:nsentences=16, article-summary:sample_size=4727.21
| epoch 010:    200 / 344 loss=2.846, nll_loss=0.726, ppl=1.65, wps=3045, ups=0, wpb=14052.328, bsz=48.000, num_updates=3284, lr=3.86484e-05, gnorm=1.519, clip=1.000, oom=0.000, loss_scale=0.062, wall=16654, train_wall=1.08882e+06, gold_gen_by      ol:article:loss=0.159427, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9372.82, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.68686, article-summary:nll_loss=0.725556, arti      cle-summary:ntokens=4679.51, article-summary:nsentences=16, article-summary:sample_size=4679.51
| epoch 010:    250 / 344 loss=2.847, nll_loss=0.727, ppl=1.66, wps=3051, ups=0, wpb=14129.546, bsz=48.000, num_updates=3334, lr=3.85958e-05, gnorm=1.503, clip=1.000, oom=0.000, loss_scale=0.062, wall=16889, train_wall=1.08905e+06, gold_gen_by      ol:article:loss=0.159404, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9439.92, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.68783, article-summary:nll_loss=0.727439, arti      cle-summary:ntokens=4689.63, article-summary:nsentences=16, article-summary:sample_size=4689.63
| epoch 010:    300 / 344 loss=2.846, nll_loss=0.727, ppl=1.65, wps=3035, ups=0, wpb=14072.010, bsz=48.000, num_updates=3384, lr=3.85432e-05, gnorm=1.501, clip=1.000, oom=0.000, loss_scale=0.062, wall=17123, train_wall=1.08929e+06, gold_gen_by      ol:article:loss=0.159399, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9399.67, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.68692, article-summary:nll_loss=0.726834, arti      cle-summary:ntokens=4672.34, article-summary:nsentences=16, article-summary:sample_size=4672.34
| epoch 010 | loss 2.847 | nll_loss 0.728 | ppl 1.66 | wps 3041 | ups 0 | wpb 14106.456 | bsz 47.985 | num_updates 3427 | lr 3.84979e-05 | gnorm 1.495 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 17323 | train_wall 1.08949e+06 | gold_gen      _byol:article:loss 0.159328 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9427.45 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.68741 | article-summary:nll_loss 0.728      03 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 010 | valid on 'valid' subset | loss 3.448 | nll_loss 1.584 | ppl 3 | num_updates 3427 | best_loss 3.35637 | article-summary:loss 3.42274 | article-summary:nll_loss 1.55766 | article-summary:ntokens 1140.18 | article-summary:nsentences       3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 10 @ 3427 updates) (writing took 7.941532135009766 seconds)
| epoch 011:     50 / 344 loss=2.739, nll_loss=0.607, ppl=1.52, wps=3014, ups=0, wpb=13869.314, bsz=48.000, num_updates=3478, lr=3.84442e-05, gnorm=1.372, clip=1.000, oom=0.000, loss_scale=0.125, wall=17572, train_wall=1.08972e+06, article-sum      mary:loss=2.57995, article-summary:nll_loss=0.607788, article-summary:ntokens=4585.94, article-summary:nsentences=16, article-summary:sample_size=4585.94, gold_gen_byol:article:loss=0.158837, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9283.37, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 011:    100 / 344 loss=2.757, nll_loss=0.627, ppl=1.54, wps=3048, ups=0, wpb=14144.653, bsz=48.000, num_updates=3528, lr=3.83916e-05, gnorm=1.390, clip=1.000, oom=0.000, loss_scale=0.125, wall=17806, train_wall=1.08996e+06, article-sum      mary:loss=2.59866, article-summary:nll_loss=0.62794, article-summary:ntokens=4685.13, article-summary:nsentences=16, article-summary:sample_size=4685.13, gold_gen_byol:article:loss=0.158805, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9459.52, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 011:    150 / 344 loss=2.765, nll_loss=0.635, ppl=1.55, wps=3037, ups=0, wpb=13932.020, bsz=48.000, num_updates=3578, lr=3.83389e-05, gnorm=1.415, clip=1.000, oom=0.000, loss_scale=0.125, wall=18030, train_wall=1.09018e+06, article-sum      mary:loss=2.60577, article-summary:nll_loss=0.635659, article-summary:ntokens=4646.14, article-summary:nsentences=16, article-summary:sample_size=4646.14, gold_gen_byol:article:loss=0.159019, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9285.88, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 011:    200 / 344 loss=2.766, nll_loss=0.638, ppl=1.56, wps=3048, ups=0, wpb=14031.925, bsz=48.000, num_updates=3628, lr=3.82863e-05, gnorm=1.490, clip=1.000, oom=0.000, loss_scale=0.125, wall=18263, train_wall=1.09041e+06, article-sum      mary:loss=2.60721, article-summary:nll_loss=0.638303, article-summary:ntokens=4670.91, article-summary:nsentences=16, article-summary:sample_size=4670.91, gold_gen_byol:article:loss=0.158963, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9361.01, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 011:    250 / 344 loss=2.769, nll_loss=0.641, ppl=1.56, wps=3058, ups=0, wpb=14134.024, bsz=48.000, num_updates=3678, lr=3.82337e-05, gnorm=1.502, clip=1.000, oom=0.000, loss_scale=0.125, wall=18497, train_wall=1.09064e+06, article-sum      mary:loss=2.61013, article-summary:nll_loss=0.642397, article-summary:ntokens=4692.1, article-summary:nsentences=16, article-summary:sample_size=4692.1, gold_gen_byol:article:loss=0.15889, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9441.93, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 011:    300 / 344 loss=2.767, nll_loss=0.639, ppl=1.56, wps=3062, ups=0, wpb=14167.638, bsz=48.000, num_updates=3728, lr=3.81811e-05, gnorm=1.491, clip=1.000, oom=0.000, loss_scale=0.125, wall=18730, train_wall=1.09088e+06, article-sum      mary:loss=2.60782, article-summary:nll_loss=0.640396, article-summary:ntokens=4700.21, article-summary:nsentences=16, article-summary:sample_size=4700.21, gold_gen_byol:article:loss=0.158873, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9467.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 011 | loss 2.768 | nll_loss 0.641 | ppl 1.56 | wps 3060 | ups 0 | wpb 14112.875 | bsz 47.985 | num_updates 3771 | lr 3.81358e-05 | gnorm 1.485 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 18924 | train_wall 1.09107e+06 | article-      summary:loss 2.60865 | article-summary:nll_loss 0.641582 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.158909 | gold_gen_byol:article:nll_loss 0 | gold_gen      _byol:article:ntokens 9433.87 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 011 | valid on 'valid' subset | loss 3.480 | nll_loss 1.625 | ppl 3.08 | num_updates 3771 | best_loss 3.35637 | article-summary:loss 3.45225 | article-summary:nll_loss 1.59529 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 11 @ 3771 updates) (writing took 8.077064275741577 seconds)
| epoch 012:     50 / 344 loss=2.699, nll_loss=0.564, ppl=1.48, wps=3061, ups=0, wpb=14310.373, bsz=48.000, num_updates=3822, lr=3.80821e-05, gnorm=1.347, clip=1.000, oom=0.000, loss_scale=0.125, wall=19175, train_wall=1.09131e+06, article-sum      mary:loss=2.54049, article-summary:nll_loss=0.563411, article-summary:ntokens=4744.57, article-summary:nsentences=16, article-summary:sample_size=4744.57, gold_gen_byol:article:loss=0.158871, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9565.8, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 012:    100 / 344 loss=2.700, nll_loss=0.566, ppl=1.48, wps=3035, ups=0, wpb=14228.921, bsz=48.000, num_updates=3872, lr=3.80295e-05, gnorm=1.373, clip=1.000, oom=0.000, loss_scale=0.125, wall=19410, train_wall=1.09154e+06, article-sum      mary:loss=2.54159, article-summary:nll_loss=0.56519, article-summary:ntokens=4692.05, article-summary:nsentences=16, article-summary:sample_size=4692.05, gold_gen_byol:article:loss=0.158659, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9536.87, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| WARNING: overflow detected, setting loss scale to: 0.0625
| epoch 012:    150 / 344 loss=2.702, nll_loss=0.569, ppl=1.48, wps=3014, ups=0, wpb=14143.467, bsz=48.000, num_updates=3921, lr=3.79779e-05, gnorm=1.556, clip=1.000, oom=0.000, loss_scale=0.062, wall=19641, train_wall=1.09177e+06, article-sum      mary:loss=2.5437, article-summary:nll_loss=0.569078, article-summary:ntokens=4678.64, article-summary:nsentences=16, article-summary:sample_size=4678.64, gold_gen_byol:article:loss=0.158628, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9464.83, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 012:    200 / 344 loss=2.700, nll_loss=0.568, ppl=1.48, wps=3019, ups=0, wpb=14002.875, bsz=48.000, num_updates=3971, lr=3.79253e-05, gnorm=1.540, clip=1.000, oom=0.000, loss_scale=0.062, wall=19865, train_wall=1.092e+06, article-summa      ry:loss=2.54141, article-summary:nll_loss=0.567505, article-summary:ntokens=4650.64, article-summary:nsentences=16, article-summary:sample_size=4650.64, gold_gen_byol:article:loss=0.158643, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9352.24, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 012:    250 / 344 loss=2.701, nll_loss=0.570, ppl=1.48, wps=3049, ups=0, wpb=14097.916, bsz=48.000, num_updates=4021, lr=3.78726e-05, gnorm=1.521, clip=1.000, oom=0.000, loss_scale=0.062, wall=20093, train_wall=1.09222e+06, article-sum      mary:loss=2.54292, article-summary:nll_loss=0.569364, article-summary:ntokens=4675.9, article-summary:nsentences=16, article-summary:sample_size=4675.9, gold_gen_byol:article:loss=0.158479, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9422.02, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 012:    300 / 344 loss=2.703, nll_loss=0.573, ppl=1.49, wps=3053, ups=0, wpb=14077.447, bsz=48.000, num_updates=4071, lr=3.782e-05, gnorm=1.520, clip=1.000, oom=0.000, loss_scale=0.062, wall=20320, train_wall=1.09245e+06, article-summa      ry:loss=2.54497, article-summary:nll_loss=0.572245, article-summary:ntokens=4678.66, article-summary:nsentences=16, article-summary:sample_size=4678.66, gold_gen_byol:article:loss=0.158451, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9398.79, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 012 | loss 2.711 | nll_loss 0.580 | ppl 1.5 | wps 3054 | ups 0 | wpb 14064.440 | bsz 47.962 | num_updates 4114 | lr 3.77747e-05 | gnorm 1.661 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 20517 | train_wall 1.09265e+06 | article-s      ummary:loss 2.55218 | article-summary:nll_loss 0.580265 | article-summary:ntokens 4677.05 | article-summary:nsentences 15.9854 | article-summary:sample_size 4677.05 | gold_gen_byol:article:loss 0.158424 | gold_gen_byol:article:nll_loss 0 | gol      d_gen_byol:article:ntokens 9387.39 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 012 | valid on 'valid' subset | loss 3.514 | nll_loss 1.662 | ppl 3.16 | num_updates 4114 | best_loss 3.35637 | article-summary:loss 3.48499 | article-summary:nll_loss 1.63205 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 12 @ 4114 updates) (writing took 8.108500242233276 seconds)
| epoch 013:     50 / 344 loss=2.642, nll_loss=0.506, ppl=1.42, wps=2464, ups=0, wpb=14163.961, bsz=48.000, num_updates=4165, lr=3.77211e-05, gnorm=1.415, clip=1.000, oom=0.000, loss_scale=0.062, wall=20825, train_wall=1.09294e+06, article-sum      mary:loss=2.48397, article-summary:nll_loss=0.505104, article-summary:ntokens=4722.16, article-summary:nsentences=16, article-summary:sample_size=4722.16, gold_gen_byol:article:loss=0.15806, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9441.8, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 013:    100 / 344 loss=2.641, nll_loss=0.505, ppl=1.42, wps=2466, ups=0, wpb=14166.505, bsz=48.000, num_updates=4215, lr=3.76684e-05, gnorm=1.526, clip=1.000, oom=0.000, loss_scale=0.062, wall=21112, train_wall=1.09323e+06, article-sum      mary:loss=2.483, article-summary:nll_loss=0.504456, article-summary:ntokens=4702.86, article-summary:nsentences=16, article-summary:sample_size=4702.86, gold_gen_byol:article:loss=0.157939, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9463.64, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 013:    150 / 344 loss=2.645, nll_loss=0.510, ppl=1.42, wps=2478, ups=0, wpb=14220.166, bsz=48.000, num_updates=4265, lr=3.76158e-05, gnorm=1.491, clip=1.000, oom=0.000, loss_scale=0.062, wall=21398, train_wall=1.09352e+06, article-sum      mary:loss=2.48705, article-summary:nll_loss=0.509182, article-summary:ntokens=4707.26, article-summary:nsentences=16, article-summary:sample_size=4707.26, gold_gen_byol:article:loss=0.157755, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9512.9, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 013:    200 / 344 loss=2.646, nll_loss=0.511, ppl=1.43, wps=2481, ups=0, wpb=14215.736, bsz=48.000, num_updates=4315, lr=3.75632e-05, gnorm=1.550, clip=1.000, oom=0.000, loss_scale=0.062, wall=21683, train_wall=1.0938e+06, article-summ      ary:loss=2.48843, article-summary:nll_loss=0.510837, article-summary:ntokens=4700.45, article-summary:nsentences=16, article-summary:sample_size=4700.45, gold_gen_byol:article:loss=0.157595, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9515.28, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 013:    250 / 344 loss=2.647, nll_loss=0.514, ppl=1.43, wps=2473, ups=0, wpb=14188.195, bsz=48.000, num_updates=4365, lr=3.75105e-05, gnorm=1.544, clip=1.000, oom=0.000, loss_scale=0.062, wall=21971, train_wall=1.09409e+06, article-sum      mary:loss=2.48978, article-summary:nll_loss=0.513086, article-summary:ntokens=4690.04, article-summary:nsentences=16, article-summary:sample_size=4690.04, gold_gen_byol:article:loss=0.157571, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9498.15, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 013:    300 / 344 loss=2.652, nll_loss=0.518, ppl=1.43, wps=2468, ups=0, wpb=14159.990, bsz=48.000, num_updates=4415, lr=3.74579e-05, gnorm=1.531, clip=1.000, oom=0.000, loss_scale=0.062, wall=22259, train_wall=1.09438e+06, article-sum      mary:loss=2.49407, article-summary:nll_loss=0.517764, article-summary:ntokens=4681.56, article-summary:nsentences=16, article-summary:sample_size=4681.56, gold_gen_byol:article:loss=0.157522, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9478.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 013 | loss 2.652 | nll_loss 0.519 | ppl 1.43 | wps 2465 | ups 0 | wpb 14117.224 | bsz 47.892 | num_updates 4458 | lr 3.74126e-05 | gnorm 1.530 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 22501 | train_wall 1.09462e+06 | article-      summary:loss 2.49527 | article-summary:nll_loss 0.519388 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.157499 | gold_gen_byol:article:nll_loss 0 | gold_gen      _byol:article:ntokens 9465.74 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 013 | valid on 'valid' subset | loss 3.564 | nll_loss 1.714 | ppl 3.28 | num_updates 4458 | best_loss 3.35637 | article-summary:loss 3.53546 | article-summary:nll_loss 1.68376 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 13 @ 4458 updates) (writing took 8.213804960250854 seconds)
| epoch 014:     50 / 344 loss=2.589, nll_loss=0.450, ppl=1.37, wps=3111, ups=0, wpb=13947.961, bsz=48.000, num_updates=4509, lr=3.73589e-05, gnorm=1.616, clip=1.000, oom=0.000, loss_scale=0.062, wall=22744, train_wall=1.09484e+06, gold_gen_by      ol:article:loss=0.157277, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9332.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.4313, article-summary:nll_loss=0.450307, artic      le-summary:ntokens=4615.02, article-summary:nsentences=16, article-summary:sample_size=4615.02
| epoch 014:    100 / 344 loss=2.591, nll_loss=0.453, ppl=1.37, wps=3118, ups=0, wpb=14053.703, bsz=48.000, num_updates=4559, lr=3.73063e-05, gnorm=1.457, clip=1.000, oom=0.000, loss_scale=0.062, wall=22971, train_wall=1.09507e+06, gold_gen_by      ol:article:loss=0.15727, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9374.53, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.4333, article-summary:nll_loss=0.452785, articl      e-summary:ntokens=4679.17, article-summary:nsentences=16, article-summary:sample_size=4679.17
| epoch 014:    150 / 344 loss=2.596, nll_loss=0.459, ppl=1.37, wps=3126, ups=0, wpb=14140.086, bsz=48.000, num_updates=4609, lr=3.72537e-05, gnorm=1.521, clip=1.000, oom=0.000, loss_scale=0.062, wall=23199, train_wall=1.0953e+06, gold_gen_byo      l:article:loss=0.157095, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9462.89, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.43861, article-summary:nll_loss=0.4589, article      -summary:ntokens=4677.2, article-summary:nsentences=16, article-summary:sample_size=4677.2
| epoch 014:    200 / 344 loss=2.599, nll_loss=0.462, ppl=1.38, wps=3112, ups=0, wpb=14033.567, bsz=48.000, num_updates=4659, lr=3.72011e-05, gnorm=1.487, clip=1.000, oom=0.000, loss_scale=0.062, wall=23422, train_wall=1.09552e+06, gold_gen_by      ol:article:loss=0.157124, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9379.52, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.442, article-summary:nll_loss=0.462813, articl      e-summary:ntokens=4654.04, article-summary:nsentences=16, article-summary:sample_size=4654.04
| epoch 014:    250 / 344 loss=2.602, nll_loss=0.466, ppl=1.38, wps=3127, ups=0, wpb=14123.924, bsz=48.000, num_updates=4709, lr=3.71484e-05, gnorm=1.458, clip=1.000, oom=0.000, loss_scale=0.062, wall=23649, train_wall=1.09575e+06, gold_gen_by      ol:article:loss=0.156996, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9440.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.44527, article-summary:nll_loss=0.465989, arti      cle-summary:ntokens=4683.49, article-summary:nsentences=16, article-summary:sample_size=4683.49
| epoch 014:    300 / 344 loss=2.605, nll_loss=0.468, ppl=1.38, wps=3132, ups=0, wpb=14126.595, bsz=48.000, num_updates=4759, lr=3.70958e-05, gnorm=1.443, clip=1.000, oom=0.000, loss_scale=0.062, wall=23873, train_wall=1.09597e+06, gold_gen_by      ol:article:loss=0.156956, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9438.84, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.44799, article-summary:nll_loss=0.469034, arti      cle-summary:ntokens=4687.75, article-summary:nsentences=16, article-summary:sample_size=4687.75
| epoch 014 | loss 2.605 | nll_loss 0.468 | ppl 1.38 | wps 3130 | ups 0 | wpb 14105.154 | bsz 47.985 | num_updates 4802 | lr 3.70505e-05 | gnorm 1.428 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 24066 | train_wall 1.09616e+06 | gold_gen      _byol:article:loss 0.156928 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9426.15 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.44781 | article-summary:nll_loss 0.469      111 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 014 | valid on 'valid' subset | loss 3.603 | nll_loss 1.784 | ppl 3.44 | num_updates 4802 | best_loss 3.35637 | article-summary:loss 3.57094 | article-summary:nll_loss 1.75075 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 14 @ 4802 updates) (writing took 8.17362928390503 seconds)
| epoch 015:     50 / 344 loss=2.545, nll_loss=0.406, ppl=1.33, wps=3095, ups=0, wpb=14108.059, bsz=48.000, num_updates=4853, lr=3.69968e-05, gnorm=1.277, clip=1.000, oom=0.000, loss_scale=0.062, wall=24313, train_wall=1.0964e+06, article-summ      ary:loss=2.38819, article-summary:nll_loss=0.407688, article-summary:ntokens=4698.8, article-summary:nsentences=16, article-summary:sample_size=4698.8, gold_gen_byol:article:loss=0.156861, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9409.25, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 015:    100 / 344 loss=2.556, nll_loss=0.418, ppl=1.34, wps=3108, ups=0, wpb=14094.762, bsz=48.000, num_updates=4903, lr=3.69442e-05, gnorm=1.356, clip=1.000, oom=0.000, loss_scale=0.062, wall=24539, train_wall=1.09662e+06, article-sum      mary:loss=2.39909, article-summary:nll_loss=0.418461, article-summary:ntokens=4689.57, article-summary:nsentences=16, article-summary:sample_size=4689.57, gold_gen_byol:article:loss=0.156737, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9405.19, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 015:    150 / 344 loss=2.560, nll_loss=0.422, ppl=1.34, wps=3122, ups=0, wpb=14066.722, bsz=48.000, num_updates=4953, lr=3.68916e-05, gnorm=1.334, clip=1.000, oom=0.000, loss_scale=0.125, wall=24761, train_wall=1.09685e+06, article-sum      mary:loss=2.40288, article-summary:nll_loss=0.42234, article-summary:ntokens=4683.28, article-summary:nsentences=16, article-summary:sample_size=4683.28, gold_gen_byol:article:loss=0.156677, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9383.44, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 015:    200 / 344 loss=2.558, nll_loss=0.421, ppl=1.34, wps=3122, ups=0, wpb=14058.104, bsz=48.000, num_updates=5003, lr=3.68389e-05, gnorm=1.315, clip=1.000, oom=0.000, loss_scale=0.125, wall=24986, train_wall=1.09707e+06, article-sum      mary:loss=2.40141, article-summary:nll_loss=0.421554, article-summary:ntokens=4678.68, article-summary:nsentences=16, article-summary:sample_size=4678.68, gold_gen_byol:article:loss=0.156686, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9379.42, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 015:    250 / 344 loss=2.561, nll_loss=0.424, ppl=1.34, wps=3116, ups=0, wpb=14095.502, bsz=48.000, num_updates=5053, lr=3.67863e-05, gnorm=1.340, clip=1.000, oom=0.000, loss_scale=0.125, wall=25216, train_wall=1.0973e+06, article-summ      ary:loss=2.40476, article-summary:nll_loss=0.424905, article-summary:ntokens=4683.14, article-summary:nsentences=16, article-summary:sample_size=4683.14, gold_gen_byol:article:loss=0.156663, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9412.37, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 015:    300 / 344 loss=2.565, nll_loss=0.428, ppl=1.35, wps=3118, ups=0, wpb=14131.415, bsz=48.000, num_updates=5103, lr=3.67337e-05, gnorm=1.343, clip=1.000, oom=0.000, loss_scale=0.125, wall=25445, train_wall=1.09753e+06, article-sum      mary:loss=2.40855, article-summary:nll_loss=0.428858, article-summary:ntokens=4689.13, article-summary:nsentences=16, article-summary:sample_size=4689.13, gold_gen_byol:article:loss=0.156615, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9442.29, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 015 | loss 2.567 | nll_loss 0.429 | ppl 1.35 | wps 3115 | ups 0 | wpb 14115.480 | bsz 47.985 | num_updates 5146 | lr 3.66884e-05 | gnorm 1.356 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 25640 | train_wall 1.09772e+06 | article-      summary:loss 2.40995 | article-summary:nll_loss 0.430265 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.156614 | gold_gen_byol:article:nll_loss 0 | gold_gen      _byol:article:ntokens 9436.48 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 015 | valid on 'valid' subset | loss 3.630 | nll_loss 1.831 | ppl 3.56 | num_updates 5146 | best_loss 3.35637 | article-summary:loss 3.59867 | article-summary:nll_loss 1.79855 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 15 @ 5146 updates) (writing took 8.355802297592163 seconds)
| epoch 016:     50 / 344 loss=2.516, nll_loss=0.379, ppl=1.3, wps=3064, ups=0, wpb=13814.725, bsz=48.000, num_updates=5197, lr=3.66347e-05, gnorm=1.240, clip=1.000, oom=0.000, loss_scale=0.125, wall=25884, train_wall=1.09795e+06, article-summ      ary:loss=2.35934, article-summary:nll_loss=0.378544, article-summary:ntokens=4602.1, article-summary:nsentences=16, article-summary:sample_size=4602.1, gold_gen_byol:article:loss=0.156753, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9212.63, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 016:    100 / 344 loss=2.516, nll_loss=0.379, ppl=1.3, wps=3058, ups=0, wpb=13760.525, bsz=48.000, num_updates=5247, lr=3.65821e-05, gnorm=1.239, clip=1.000, oom=0.000, loss_scale=0.125, wall=26109, train_wall=1.09818e+06, article-summ      ary:loss=2.35952, article-summary:nll_loss=0.378793, article-summary:ntokens=4623.77, article-summary:nsentences=16, article-summary:sample_size=4623.77, gold_gen_byol:article:loss=0.156705, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9136.75, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 016:    150 / 344 loss=2.525, nll_loss=0.387, ppl=1.31, wps=3074, ups=0, wpb=14015.914, bsz=48.000, num_updates=5297, lr=3.65295e-05, gnorm=1.304, clip=1.000, oom=0.000, loss_scale=0.125, wall=26343, train_wall=1.09841e+06, article-sum      mary:loss=2.3683, article-summary:nll_loss=0.387266, article-summary:ntokens=4656.47, article-summary:nsentences=16, article-summary:sample_size=4656.47, gold_gen_byol:article:loss=0.156363, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9359.44, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 016:    200 / 344 loss=2.524, nll_loss=0.387, ppl=1.31, wps=3075, ups=0, wpb=14036.582, bsz=48.000, num_updates=5347, lr=3.64768e-05, gnorm=1.288, clip=1.000, oom=0.000, loss_scale=0.125, wall=26572, train_wall=1.09864e+06, article-sum      mary:loss=2.36812, article-summary:nll_loss=0.38754, article-summary:ntokens=4662.41, article-summary:nsentences=16, article-summary:sample_size=4662.41, gold_gen_byol:article:loss=0.156299, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9374.17, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 016:    250 / 344 loss=2.529, nll_loss=0.392, ppl=1.31, wps=3087, ups=0, wpb=14121.502, bsz=48.000, num_updates=5397, lr=3.64242e-05, gnorm=1.288, clip=1.000, oom=0.000, loss_scale=0.125, wall=26803, train_wall=1.09887e+06, article-sum      mary:loss=2.37304, article-summary:nll_loss=0.392066, article-summary:ntokens=4694.35, article-summary:nsentences=16, article-summary:sample_size=4694.35, gold_gen_byol:article:loss=0.156284, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9427.16, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 016:    300 / 344 loss=2.533, nll_loss=0.396, ppl=1.32, wps=3095, ups=0, wpb=14137.252, bsz=48.000, num_updates=5447, lr=3.63716e-05, gnorm=1.291, clip=1.000, oom=0.000, loss_scale=0.125, wall=27029, train_wall=1.0991e+06, article-summ      ary:loss=2.37705, article-summary:nll_loss=0.396373, article-summary:ntokens=4705.61, article-summary:nsentences=16, article-summary:sample_size=4705.61, gold_gen_byol:article:loss=0.156304, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9431.64, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 016 | loss 2.534 | nll_loss 0.396 | ppl 1.32 | wps 3078 | ups 0 | wpb 14054.817 | bsz 47.962 | num_updates 5490 | lr 3.63263e-05 | gnorm 1.295 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 27225 | train_wall 1.09929e+06 | article-      summary:loss 2.37718 | article-summary:nll_loss 0.39654 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.156361 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9375.81 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 016 | valid on 'valid' subset | loss 3.665 | nll_loss 1.874 | ppl 3.67 | num_updates 5490 | best_loss 3.35637 | article-summary:loss 3.63431 | article-summary:nll_loss 1.8417 | article-summary:ntokens 1140.18 | article-summary:nsentenc      es 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 16 @ 5490 updates) (writing took 8.362689018249512 seconds)
| epoch 017:     50 / 344 loss=2.492, nll_loss=0.354, ppl=1.28, wps=2405, ups=0, wpb=14258.510, bsz=48.000, num_updates=5541, lr=3.62726e-05, gnorm=1.141, clip=1.000, oom=0.000, loss_scale=0.125, wall=27541, train_wall=1.09959e+06, article-sum      mary:loss=2.33594, article-summary:nll_loss=0.354066, article-summary:ntokens=4728, article-summary:nsentences=16, article-summary:sample_size=4728, gold_gen_byol:article:loss=0.156019, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9530.51, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 017:    100 / 344 loss=2.493, nll_loss=0.356, ppl=1.28, wps=2434, ups=0, wpb=14204.663, bsz=48.000, num_updates=5591, lr=3.622e-05, gnorm=1.184, clip=1.000, oom=0.000, loss_scale=0.125, wall=27828, train_wall=1.09988e+06, article-summa      ry:loss=2.33684, article-summary:nll_loss=0.356428, article-summary:ntokens=4736.35, article-summary:nsentences=16, article-summary:sample_size=4736.35, gold_gen_byol:article:loss=0.156118, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9468.32, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 017:    150 / 344 loss=2.497, nll_loss=0.360, ppl=1.28, wps=2451, ups=0, wpb=14186.285, bsz=48.000, num_updates=5641, lr=3.61674e-05, gnorm=1.208, clip=1.000, oom=0.000, loss_scale=0.125, wall=28113, train_wall=1.10016e+06, article-sum      mary:loss=2.34094, article-summary:nll_loss=0.360284, article-summary:ntokens=4721.12, article-summary:nsentences=16, article-summary:sample_size=4721.12, gold_gen_byol:article:loss=0.155907, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9465.17, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 017:    200 / 344 loss=2.500, nll_loss=0.364, ppl=1.29, wps=2456, ups=0, wpb=14205.274, bsz=48.000, num_updates=5691, lr=3.61147e-05, gnorm=1.213, clip=1.000, oom=0.000, loss_scale=0.125, wall=28401, train_wall=1.10045e+06, article-sum      mary:loss=2.34459, article-summary:nll_loss=0.364305, article-summary:ntokens=4726.61, article-summary:nsentences=16, article-summary:sample_size=4726.61, gold_gen_byol:article:loss=0.155894, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9478.67, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 017:    250 / 344 loss=2.501, nll_loss=0.365, ppl=1.29, wps=2449, ups=0, wpb=14128.167, bsz=48.000, num_updates=5741, lr=3.60621e-05, gnorm=1.219, clip=1.000, oom=0.000, loss_scale=0.125, wall=28687, train_wall=1.10074e+06, article-sum      mary:loss=2.34501, article-summary:nll_loss=0.364683, article-summary:ntokens=4700.9, article-summary:nsentences=16, article-summary:sample_size=4700.9, gold_gen_byol:article:loss=0.155904, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9427.27, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 017:    300 / 344 loss=2.503, nll_loss=0.367, ppl=1.29, wps=2456, ups=0, wpb=14173.764, bsz=48.000, num_updates=5791, lr=3.60095e-05, gnorm=1.253, clip=1.000, oom=0.000, loss_scale=0.125, wall=28976, train_wall=1.10103e+06, article-sum      mary:loss=2.34683, article-summary:nll_loss=0.366971, article-summary:ntokens=4709.21, article-summary:nsentences=16, article-summary:sample_size=4709.21, gold_gen_byol:article:loss=0.155857, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9464.56, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 017 | loss 2.504 | nll_loss 0.368 | ppl 1.29 | wps 2449 | ups 0 | wpb 14081.956 | bsz 47.892 | num_updates 5834 | lr 3.59642e-05 | gnorm 1.263 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 29217 | train_wall 1.10127e+06 | article-      summary:loss 2.34805 | article-summary:nll_loss 0.368409 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.155907 | gold_gen_byol:article:nll_loss 0 | gold_gen      _byol:article:ntokens 9430.37 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 017 | valid on 'valid' subset | loss 3.672 | nll_loss 1.878 | ppl 3.68 | num_updates 5834 | best_loss 3.35637 | article-summary:loss 3.64205 | article-summary:nll_loss 1.8466 | article-summary:ntokens 1140.18 | article-summary:nsentenc      es 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 17 @ 5834 updates) (writing took 7.997170686721802 seconds)
| epoch 018:     50 / 344 loss=2.474, nll_loss=0.337, ppl=1.26, wps=3063, ups=0, wpb=13767.490, bsz=48.000, num_updates=5885, lr=3.59105e-05, gnorm=1.191, clip=1.000, oom=0.000, loss_scale=0.125, wall=29461, train_wall=1.1015e+06, gold_gen_byo      l:article:loss=0.156186, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9209.02, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.31813, article-summary:nll_loss=0.336755, artic      le-summary:ntokens=4558.47, article-summary:nsentences=16, article-summary:sample_size=4558.47
| epoch 018:    100 / 344 loss=2.478, nll_loss=0.340, ppl=1.27, wps=3133, ups=0, wpb=14240.525, bsz=48.000, num_updates=5935, lr=3.58579e-05, gnorm=1.246, clip=1.000, oom=0.000, loss_scale=0.125, wall=29691, train_wall=1.10173e+06, gold_gen_by      ol:article:loss=0.156139, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9544.48, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.32149, article-summary:nll_loss=0.340412, arti      cle-summary:ntokens=4696.05, article-summary:nsentences=16, article-summary:sample_size=4696.05
| epoch 018:    150 / 344 loss=2.476, nll_loss=0.339, ppl=1.27, wps=3146, ups=0, wpb=14345.013, bsz=48.000, num_updates=5985, lr=3.58053e-05, gnorm=1.221, clip=1.000, oom=0.000, loss_scale=0.250, wall=29920, train_wall=1.10196e+06, gold_gen_by      ol:article:loss=0.156167, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9618.17, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.31948, article-summary:nll_loss=0.339299, arti      cle-summary:ntokens=4726.84, article-summary:nsentences=16, article-summary:sample_size=4726.84
| epoch 018:    200 / 344 loss=2.477, nll_loss=0.341, ppl=1.27, wps=3144, ups=0, wpb=14328.791, bsz=48.000, num_updates=6035, lr=3.57526e-05, gnorm=1.215, clip=1.000, oom=0.000, loss_scale=0.250, wall=30148, train_wall=1.10218e+06, gold_gen_by      ol:article:loss=0.156338, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9597.93, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.3206, article-summary:nll_loss=0.340792, artic      le-summary:ntokens=4730.86, article-summary:nsentences=16, article-summary:sample_size=4730.86
| epoch 018:    250 / 344 loss=2.479, nll_loss=0.342, ppl=1.27, wps=3128, ups=0, wpb=14232.884, bsz=48.000, num_updates=6085, lr=3.57e-05, gnorm=1.225, clip=1.000, oom=0.000, loss_scale=0.250, wall=30374, train_wall=1.10241e+06, gold_gen_byol:      article:loss=0.156522, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9521.02, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.32234, article-summary:nll_loss=0.342763, article      -summary:ntokens=4711.86, article-summary:nsentences=16, article-summary:sample_size=4711.86
| epoch 018:    300 / 344 loss=2.479, nll_loss=0.343, ppl=1.27, wps=3126, ups=0, wpb=14193.565, bsz=48.000, num_updates=6135, lr=3.56474e-05, gnorm=1.222, clip=1.000, oom=0.000, loss_scale=0.250, wall=30599, train_wall=1.10263e+06, gold_gen_by      ol:article:loss=0.156612, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9489.91, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.32261, article-summary:nll_loss=0.343133, arti      cle-summary:ntokens=4703.65, article-summary:nsentences=16, article-summary:sample_size=4703.65
| epoch 018 | loss 2.480 | nll_loss 0.343 | ppl 1.27 | wps 3118 | ups 0 | wpb 14121.817 | bsz 47.985 | num_updates 6178 | lr 3.56021e-05 | gnorm 1.226 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 30790 | train_wall 1.10282e+06 | gold_gen      _byol:article:loss 0.156765 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9442.81 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.32314 | article-summary:nll_loss 0.343      876 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 018 | valid on 'valid' subset | loss 3.708 | nll_loss 1.925 | ppl 3.8 | num_updates 6178 | best_loss 3.35637 | article-summary:loss 3.67767 | article-summary:nll_loss 1.89315 | article-summary:ntokens 1140.18 | article-summary:nsentenc      es 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 18 @ 6178 updates) (writing took 8.282793045043945 seconds)
| epoch 019:     50 / 344 loss=2.449, nll_loss=0.314, ppl=1.24, wps=3106, ups=0, wpb=14145.294, bsz=48.000, num_updates=6229, lr=3.55484e-05, gnorm=1.138, clip=1.000, oom=0.000, loss_scale=0.250, wall=31037, train_wall=1.10306e+06, article-sum      mary:loss=2.29123, article-summary:nll_loss=0.313129, article-summary:ntokens=4674.86, article-summary:nsentences=16, article-summary:sample_size=4674.86, gold_gen_byol:article:loss=0.157897, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9470.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 019:    100 / 344 loss=2.455, nll_loss=0.318, ppl=1.25, wps=3119, ups=0, wpb=14154.950, bsz=48.000, num_updates=6279, lr=3.54958e-05, gnorm=1.170, clip=1.000, oom=0.000, loss_scale=0.250, wall=31263, train_wall=1.10328e+06, article-sum      mary:loss=2.29701, article-summary:nll_loss=0.318645, article-summary:ntokens=4695.9, article-summary:nsentences=16, article-summary:sample_size=4695.9, gold_gen_byol:article:loss=0.157862, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9459.05, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 019:    150 / 344 loss=2.457, nll_loss=0.321, ppl=1.25, wps=3126, ups=0, wpb=14155.762, bsz=48.000, num_updates=6329, lr=3.54432e-05, gnorm=1.171, clip=1.000, oom=0.000, loss_scale=0.250, wall=31488, train_wall=1.10351e+06, article-sum      mary:loss=2.29865, article-summary:nll_loss=0.320846, article-summary:ntokens=4687.18, article-summary:nsentences=16, article-summary:sample_size=4687.18, gold_gen_byol:article:loss=0.158082, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9468.58, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 019:    200 / 344 loss=2.460, nll_loss=0.323, ppl=1.25, wps=3114, ups=0, wpb=14093.597, bsz=48.000, num_updates=6379, lr=3.53905e-05, gnorm=1.181, clip=1.000, oom=0.000, loss_scale=0.250, wall=31714, train_wall=1.10373e+06, article-sum      mary:loss=2.30118, article-summary:nll_loss=0.323287, article-summary:ntokens=4678.69, article-summary:nsentences=16, article-summary:sample_size=4678.69, gold_gen_byol:article:loss=0.158334, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9414.91, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 019:    250 / 344 loss=2.463, nll_loss=0.326, ppl=1.25, wps=3113, ups=0, wpb=14087.590, bsz=48.000, num_updates=6429, lr=3.53379e-05, gnorm=1.216, clip=1.000, oom=0.000, loss_scale=0.250, wall=31940, train_wall=1.10396e+06, article-sum      mary:loss=2.30462, article-summary:nll_loss=0.3267, article-summary:ntokens=4671.57, article-summary:nsentences=16, article-summary:sample_size=4671.57, gold_gen_byol:article:loss=0.158631, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9416.02, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 019:    300 / 344 loss=2.465, nll_loss=0.327, ppl=1.25, wps=3121, ups=0, wpb=14139.096, bsz=48.000, num_updates=6479, lr=3.52853e-05, gnorm=1.255, clip=1.000, oom=0.000, loss_scale=0.250, wall=32168, train_wall=1.10419e+06, article-sum      mary:loss=2.30558, article-summary:nll_loss=0.327514, article-summary:ntokens=4690.76, article-summary:nsentences=16, article-summary:sample_size=4690.76, gold_gen_byol:article:loss=0.158979, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9448.33, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 019 | loss 2.464 | nll_loss 0.327 | ppl 1.25 | wps 3118 | ups 0 | wpb 14116.305 | bsz 47.985 | num_updates 6522 | lr 3.524e-05 | gnorm 1.263 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 32362 | train_wall 1.10438e+06 | article-su      mmary:loss 2.30504 | article-summary:nll_loss 0.327213 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.159364 | gold_gen_byol:article:nll_loss 0 | gold_gen_b      yol:article:ntokens 9437.3 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 019 | valid on 'valid' subset | loss 3.722 | nll_loss 1.941 | ppl 3.84 | num_updates 6522 | best_loss 3.35637 | article-summary:loss 3.69116 | article-summary:nll_loss 1.90895 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 19 @ 6522 updates) (writing took 8.270987510681152 seconds)
| epoch 020:     50 / 344 loss=2.438, nll_loss=0.300, ppl=1.23, wps=3089, ups=0, wpb=13987.098, bsz=48.000, num_updates=6573, lr=3.51863e-05, gnorm=1.081, clip=1.000, oom=0.000, loss_scale=0.250, wall=32607, train_wall=1.10461e+06, article-sum      mary:loss=2.27548, article-summary:nll_loss=0.300477, article-summary:ntokens=4645.22, article-summary:nsentences=16, article-summary:sample_size=4645.22, gold_gen_byol:article:loss=0.162859, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9341.88, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 020:    100 / 344 loss=2.444, nll_loss=0.305, ppl=1.24, wps=3061, ups=0, wpb=13938.752, bsz=48.000, num_updates=6623, lr=3.51337e-05, gnorm=1.136, clip=1.000, oom=0.000, loss_scale=0.250, wall=32836, train_wall=1.10484e+06, article-sum      mary:loss=2.28103, article-summary:nll_loss=0.305387, article-summary:ntokens=4627.03, article-summary:nsentences=16, article-summary:sample_size=4627.03, gold_gen_byol:article:loss=0.163233, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9311.72, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 020:    150 / 344 loss=2.446, nll_loss=0.307, ppl=1.24, wps=3062, ups=0, wpb=13934.119, bsz=48.000, num_updates=6673, lr=3.50811e-05, gnorm=1.141, clip=1.000, oom=0.000, loss_scale=0.250, wall=33063, train_wall=1.10507e+06, article-sum      mary:loss=2.28352, article-summary:nll_loss=0.306911, article-summary:ntokens=4632.61, article-summary:nsentences=16, article-summary:sample_size=4632.61, gold_gen_byol:article:loss=0.162573, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9301.51, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 020:    200 / 344 loss=2.445, nll_loss=0.307, ppl=1.24, wps=3074, ups=0, wpb=14021.577, bsz=48.000, num_updates=6723, lr=3.50284e-05, gnorm=1.140, clip=1.000, oom=0.000, loss_scale=0.250, wall=33293, train_wall=1.1053e+06, article-summ      ary:loss=2.28315, article-summary:nll_loss=0.306999, article-summary:ntokens=4639.15, article-summary:nsentences=16, article-summary:sample_size=4639.15, gold_gen_byol:article:loss=0.161976, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9382.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 020:    250 / 344 loss=2.447, nll_loss=0.309, ppl=1.24, wps=3082, ups=0, wpb=14099.637, bsz=48.000, num_updates=6773, lr=3.49758e-05, gnorm=1.144, clip=1.000, oom=0.000, loss_scale=0.250, wall=33524, train_wall=1.10553e+06, article-sum      mary:loss=2.28558, article-summary:nll_loss=0.309284, article-summary:ntokens=4668.2, article-summary:nsentences=16, article-summary:sample_size=4668.2, gold_gen_byol:article:loss=0.161536, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9431.44, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 020:    300 / 344 loss=2.448, nll_loss=0.311, ppl=1.24, wps=3091, ups=0, wpb=14155.449, bsz=48.000, num_updates=6823, lr=3.49232e-05, gnorm=1.150, clip=1.000, oom=0.000, loss_scale=0.250, wall=33754, train_wall=1.10576e+06, article-sum      mary:loss=2.28682, article-summary:nll_loss=0.31055, article-summary:ntokens=4686.65, article-summary:nsentences=16, article-summary:sample_size=4686.65, gold_gen_byol:article:loss=0.160984, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9468.8, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 020 | loss 2.448 | nll_loss 0.312 | ppl 1.24 | wps 3085 | ups 0 | wpb 14119.549 | bsz 47.962 | num_updates 6866 | lr 3.48779e-05 | gnorm 1.159 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 33950 | train_wall 1.10595e+06 | article-      summary:loss 2.2878 | article-summary:nll_loss 0.311542 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.160633 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9440.55 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 020 | valid on 'valid' subset | loss 3.756 | nll_loss 1.974 | ppl 3.93 | num_updates 6866 | best_loss 3.35637 | article-summary:loss 3.72996 | article-summary:nll_loss 1.94689 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 20 @ 6866 updates) (writing took 7.936328172683716 seconds)
| epoch 021:     50 / 344 loss=2.428, nll_loss=0.293, ppl=1.23, wps=2482, ups=0, wpb=14259.843, bsz=48.000, num_updates=6917, lr=3.48242e-05, gnorm=1.110, clip=1.000, oom=0.000, loss_scale=0.250, wall=34257, train_wall=1.10625e+06, article-sum      mary:loss=2.27033, article-summary:nll_loss=0.293084, article-summary:ntokens=4723.84, article-summary:nsentences=16, article-summary:sample_size=4723.84, gold_gen_byol:article:loss=0.158023, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9536, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 021:    100 / 344 loss=2.429, nll_loss=0.294, ppl=1.23, wps=2474, ups=0, wpb=14163.614, bsz=48.000, num_updates=6967, lr=3.47716e-05, gnorm=1.133, clip=1.000, oom=0.000, loss_scale=0.250, wall=34542, train_wall=1.10653e+06, article-sum      mary:loss=2.27112, article-summary:nll_loss=0.294305, article-summary:ntokens=4715.61, article-summary:nsentences=16, article-summary:sample_size=4715.61, gold_gen_byol:article:loss=0.157924, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9448, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 021:    150 / 344 loss=2.426, nll_loss=0.293, ppl=1.23, wps=2457, ups=0, wpb=14021.033, bsz=48.000, num_updates=7017, lr=3.47189e-05, gnorm=1.121, clip=1.000, oom=0.000, loss_scale=0.500, wall=34826, train_wall=1.10681e+06, article-sum      mary:loss=2.26849, article-summary:nll_loss=0.292789, article-summary:ntokens=4668.26, article-summary:nsentences=16, article-summary:sample_size=4668.26, gold_gen_byol:article:loss=0.157313, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9352.77, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 021:    200 / 344 loss=2.426, nll_loss=0.294, ppl=1.23, wps=2467, ups=0, wpb=14087.050, bsz=48.000, num_updates=7067, lr=3.46663e-05, gnorm=1.127, clip=1.000, oom=0.000, loss_scale=0.500, wall=35112, train_wall=1.1071e+06, article-summ      ary:loss=2.26944, article-summary:nll_loss=0.294348, article-summary:ntokens=4680.32, article-summary:nsentences=16, article-summary:sample_size=4680.32, gold_gen_byol:article:loss=0.156772, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9406.73, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 021:    250 / 344 loss=2.426, nll_loss=0.295, ppl=1.23, wps=2474, ups=0, wpb=14128.199, bsz=48.000, num_updates=7117, lr=3.46137e-05, gnorm=1.126, clip=1.000, oom=0.000, loss_scale=0.500, wall=35398, train_wall=1.10738e+06, article-sum      mary:loss=2.26999, article-summary:nll_loss=0.29516, article-summary:ntokens=4683.43, article-summary:nsentences=16, article-summary:sample_size=4683.43, gold_gen_byol:article:loss=0.155889, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9444.76, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 021:    300 / 344 loss=2.427, nll_loss=0.297, ppl=1.23, wps=2469, ups=0, wpb=14135.588, bsz=48.000, num_updates=7167, lr=3.45611e-05, gnorm=1.133, clip=1.000, oom=0.000, loss_scale=0.500, wall=35687, train_wall=1.10768e+06, article-sum      mary:loss=2.272, article-summary:nll_loss=0.296882, article-summary:ntokens=4678.17, article-summary:nsentences=16, article-summary:sample_size=4678.17, gold_gen_byol:article:loss=0.155295, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9457.42, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 021 | loss 2.428 | nll_loss 0.298 | ppl 1.23 | wps 2471 | ups 0 | wpb 14111.363 | bsz 47.892 | num_updates 7210 | lr 3.45158e-05 | gnorm 1.132 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 35929 | train_wall 1.10792e+06 | article-      summary:loss 2.27312 | article-summary:nll_loss 0.297993 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.15484 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9459.86 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 021 | valid on 'valid' subset | loss 3.769 | nll_loss 2.008 | ppl 4.02 | num_updates 7210 | best_loss 3.35637 | article-summary:loss 3.73749 | article-summary:nll_loss 1.97503 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 21 @ 7210 updates) (writing took 7.392687082290649 seconds)
| epoch 022:     50 / 344 loss=2.408, nll_loss=0.284, ppl=1.22, wps=3131, ups=0, wpb=14131.980, bsz=48.000, num_updates=7261, lr=3.44621e-05, gnorm=1.090, clip=1.000, oom=0.000, loss_scale=0.500, wall=36172, train_wall=1.10814e+06, gold_gen_by      ol:article:loss=0.149954, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9466.51, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.25791, article-summary:nll_loss=0.28431, artic      le-summary:ntokens=4665.47, article-summary:nsentences=16, article-summary:sample_size=4665.47
| epoch 022:    100 / 344 loss=2.409, nll_loss=0.285, ppl=1.22, wps=3121, ups=0, wpb=14074.545, bsz=48.000, num_updates=7311, lr=3.44095e-05, gnorm=1.075, clip=1.000, oom=0.000, loss_scale=0.500, wall=36397, train_wall=1.10837e+06, gold_gen_by      ol:article:loss=0.149323, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9448.79, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.2594, article-summary:nll_loss=0.285553, artic      le-summary:ntokens=4625.75, article-summary:nsentences=16, article-summary:sample_size=4625.75
| epoch 022:    150 / 344 loss=2.407, nll_loss=0.285, ppl=1.22, wps=3109, ups=0, wpb=13957.848, bsz=48.000, num_updates=7361, lr=3.43568e-05, gnorm=1.072, clip=1.000, oom=0.000, loss_scale=0.500, wall=36620, train_wall=1.10859e+06, gold_gen_by      ol:article:loss=0.148892, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9349.7, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.25844, article-summary:nll_loss=0.28495, articl      e-summary:ntokens=4608.15, article-summary:nsentences=16, article-summary:sample_size=4608.15
| epoch 022:    200 / 344 loss=2.409, nll_loss=0.287, ppl=1.22, wps=3103, ups=0, wpb=13977.647, bsz=48.000, num_updates=7411, lr=3.43042e-05, gnorm=1.078, clip=1.000, oom=0.000, loss_scale=0.500, wall=36847, train_wall=1.10882e+06, gold_gen_by      ol:article:loss=0.14868, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9345.85, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.26033, article-summary:nll_loss=0.286737, artic      le-summary:ntokens=4631.8, article-summary:nsentences=16, article-summary:sample_size=4631.8
| epoch 022:    250 / 344 loss=2.408, nll_loss=0.286, ppl=1.22, wps=3116, ups=0, wpb=14083.988, bsz=48.000, num_updates=7461, lr=3.42516e-05, gnorm=1.080, clip=1.000, oom=0.000, loss_scale=0.500, wall=37076, train_wall=1.10905e+06, gold_gen_by      ol:article:loss=0.148128, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9421.63, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.25995, article-summary:nll_loss=0.286529, arti      cle-summary:ntokens=4662.36, article-summary:nsentences=16, article-summary:sample_size=4662.36
| epoch 022:    300 / 344 loss=2.407, nll_loss=0.286, ppl=1.22, wps=3121, ups=0, wpb=14101.140, bsz=48.000, num_updates=7511, lr=3.41989e-05, gnorm=1.074, clip=1.000, oom=0.000, loss_scale=0.500, wall=37302, train_wall=1.10927e+06, gold_gen_by      ol:article:loss=0.147062, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9422.26, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.25959, article-summary:nll_loss=0.286466, arti      cle-summary:ntokens=4678.88, article-summary:nsentences=16, article-summary:sample_size=4678.88
| epoch 022 | loss 2.406 | nll_loss 0.286 | ppl 1.22 | wps 3123 | ups 0 | wpb 14121.747 | bsz 47.985 | num_updates 7554 | lr 3.41537e-05 | gnorm 1.077 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 37497 | train_wall 1.10947e+06 | gold_gen      _byol:article:loss 0.146335 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9442.74 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.2597 | article-summary:nll_loss 0.2866      79 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 022 | valid on 'valid' subset | loss 3.786 | nll_loss 2.038 | ppl 4.11 | num_updates 7554 | best_loss 3.35637 | article-summary:loss 3.75678 | article-summary:nll_loss 2.00674 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 22 @ 7554 updates) (writing took 8.270890474319458 seconds)
| epoch 023:     50 / 344 loss=2.388, nll_loss=0.275, ppl=1.21, wps=3116, ups=0, wpb=14154.137, bsz=48.000, num_updates=7605, lr=3.41e-05, gnorm=1.062, clip=1.000, oom=0.000, loss_scale=0.500, wall=37743, train_wall=1.1097e+06, article-summary      :loss=2.24894, article-summary:nll_loss=0.27529, article-summary:ntokens=4641.2, article-summary:nsentences=16, article-summary:sample_size=4641.2, gold_gen_byol:article:loss=0.139339, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:nt      okens=9512.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 023:    100 / 344 loss=2.384, nll_loss=0.273, ppl=1.21, wps=3094, ups=0, wpb=14049.139, bsz=48.000, num_updates=7655, lr=3.40474e-05, gnorm=1.044, clip=1.000, oom=0.000, loss_scale=0.500, wall=37970, train_wall=1.10993e+06, article-sum      mary:loss=2.24528, article-summary:nll_loss=0.273205, article-summary:ntokens=4625.61, article-summary:nsentences=16, article-summary:sample_size=4625.61, gold_gen_byol:article:loss=0.139047, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9423.52, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 023:    150 / 344 loss=2.384, nll_loss=0.273, ppl=1.21, wps=3105, ups=0, wpb=14141.775, bsz=48.000, num_updates=7705, lr=3.39947e-05, gnorm=1.042, clip=1.000, oom=0.000, loss_scale=0.500, wall=38199, train_wall=1.11016e+06, article-sum      mary:loss=2.24481, article-summary:nll_loss=0.273592, article-summary:ntokens=4677.67, article-summary:nsentences=16, article-summary:sample_size=4677.67, gold_gen_byol:article:loss=0.138968, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9464.11, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 023:    200 / 344 loss=2.385, nll_loss=0.275, ppl=1.21, wps=3103, ups=0, wpb=14150.711, bsz=48.000, num_updates=7755, lr=3.39421e-05, gnorm=1.045, clip=1.000, oom=0.000, loss_scale=0.500, wall=38428, train_wall=1.11038e+06, article-sum      mary:loss=2.24661, article-summary:nll_loss=0.275047, article-summary:ntokens=4677.66, article-summary:nsentences=16, article-summary:sample_size=4677.66, gold_gen_byol:article:loss=0.138779, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9473.05, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 023:    250 / 344 loss=2.386, nll_loss=0.275, ppl=1.21, wps=3096, ups=0, wpb=14102.139, bsz=48.000, num_updates=7805, lr=3.38895e-05, gnorm=1.050, clip=1.000, oom=0.000, loss_scale=0.500, wall=38655, train_wall=1.11061e+06, article-sum      mary:loss=2.24686, article-summary:nll_loss=0.27554, article-summary:ntokens=4657.87, article-summary:nsentences=16, article-summary:sample_size=4657.87, gold_gen_byol:article:loss=0.138739, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9444.27, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 023:    300 / 344 loss=2.386, nll_loss=0.276, ppl=1.21, wps=3104, ups=0, wpb=14147.807, bsz=48.000, num_updates=7855, lr=3.38368e-05, gnorm=1.087, clip=1.000, oom=0.000, loss_scale=0.500, wall=38884, train_wall=1.11084e+06, article-sum      mary:loss=2.24764, article-summary:nll_loss=0.276369, article-summary:ntokens=4681.12, article-summary:nsentences=16, article-summary:sample_size=4681.12, gold_gen_byol:article:loss=0.138739, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9466.68, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 023 | loss 2.388 | nll_loss 0.277 | ppl 1.21 | wps 3105 | ups 0 | wpb 14136.619 | bsz 47.985 | num_updates 7898 | lr 3.37916e-05 | gnorm 1.092 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 39078 | train_wall 1.11103e+06 | article-      summary:loss 2.24911 | article-summary:nll_loss 0.277694 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.138472 | gold_gen_byol:article:nll_loss 0 | gold_gen      _byol:article:ntokens 9457.62 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 023 | valid on 'valid' subset | loss 3.812 | nll_loss 2.067 | ppl 4.19 | num_updates 7898 | best_loss 3.35637 | article-summary:loss 3.78301 | article-summary:nll_loss 2.03578 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 23 @ 7898 updates) (writing took 8.32140564918518 seconds)
| epoch 024:     50 / 344 loss=2.366, nll_loss=0.261, ppl=1.2, wps=3119, ups=0, wpb=14074.863, bsz=48.000, num_updates=7949, lr=3.37379e-05, gnorm=0.972, clip=1.000, oom=0.000, loss_scale=0.500, wall=39322, train_wall=1.11126e+06, article-summ      ary:loss=2.23057, article-summary:nll_loss=0.261, article-summary:ntokens=4654.47, article-summary:nsentences=16, article-summary:sample_size=4654.47, gold_gen_byol:article:loss=0.135279, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9420.39, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 024:    100 / 344 loss=2.370, nll_loss=0.265, ppl=1.2, wps=3115, ups=0, wpb=14177.515, bsz=48.000, num_updates=7999, lr=3.36853e-05, gnorm=1.045, clip=1.000, oom=0.000, loss_scale=0.500, wall=39552, train_wall=1.11149e+06, article-summ      ary:loss=2.2343, article-summary:nll_loss=0.265452, article-summary:ntokens=4715.65, article-summary:nsentences=16, article-summary:sample_size=4715.65, gold_gen_byol:article:loss=0.135524, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9461.86, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 024:    150 / 344 loss=2.371, nll_loss=0.266, ppl=1.2, wps=3096, ups=0, wpb=14061.662, bsz=48.000, num_updates=8049, lr=3.36326e-05, gnorm=1.047, clip=1.000, oom=0.000, loss_scale=1.000, wall=39778, train_wall=1.11172e+06, article-summ      ary:loss=2.23473, article-summary:nll_loss=0.266068, article-summary:ntokens=4678.09, article-summary:nsentences=16, article-summary:sample_size=4678.09, gold_gen_byol:article:loss=0.136559, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9383.58, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 024:    200 / 344 loss=2.373, nll_loss=0.267, ppl=1.2, wps=3097, ups=0, wpb=14088.269, bsz=48.000, num_updates=8099, lr=3.358e-05, gnorm=1.045, clip=1.000, oom=0.000, loss_scale=1.000, wall=40007, train_wall=1.11195e+06, article-summar      y:loss=2.23602, article-summary:nll_loss=0.267122, article-summary:ntokens=4681.92, article-summary:nsentences=16, article-summary:sample_size=4681.92, gold_gen_byol:article:loss=0.13665, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9406.35, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 024:    250 / 344 loss=2.376, nll_loss=0.269, ppl=1.21, wps=3095, ups=0, wpb=14081.100, bsz=48.000, num_updates=8149, lr=3.35274e-05, gnorm=1.071, clip=1.000, oom=0.000, loss_scale=1.000, wall=40234, train_wall=1.11217e+06, article-sum      mary:loss=2.23881, article-summary:nll_loss=0.269446, article-summary:ntokens=4678.07, article-summary:nsentences=16, article-summary:sample_size=4678.07, gold_gen_byol:article:loss=0.13697, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9403.03, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 024:    300 / 344 loss=2.381, nll_loss=0.274, ppl=1.21, wps=3097, ups=0, wpb=14111.229, bsz=48.000, num_updates=8199, lr=3.34747e-05, gnorm=1.165, clip=1.000, oom=0.000, loss_scale=1.000, wall=40464, train_wall=1.1124e+06, article-summ      ary:loss=2.24306, article-summary:nll_loss=0.274057, article-summary:ntokens=4689.24, article-summary:nsentences=16, article-summary:sample_size=4689.24, gold_gen_byol:article:loss=0.138226, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9421.99, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 024 | loss 2.386 | nll_loss 0.277 | ppl 1.21 | wps 3090 | ups 0 | wpb 14088.526 | bsz 47.962 | num_updates 8242 | lr 3.34295e-05 | gnorm 1.244 | clip 1.000 | oom 0.000 | loss_scale 1.000 | wall 40661 | train_wall 1.1126e+06 | article-s      ummary:loss 2.24618 | article-summary:nll_loss 0.277037 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.139371 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9409.52 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 024 | valid on 'valid' subset | loss 3.792 | nll_loss 2.021 | ppl 4.06 | num_updates 8242 | best_loss 3.35637 | article-summary:loss 3.76252 | article-summary:nll_loss 1.98982 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 24 @ 8242 updates) (writing took 8.855035066604614 seconds)
| WARNING: overflow detected, setting loss scale to: 0.5
| WARNING: overflow detected, setting loss scale to: 0.25
| WARNING: overflow detected, setting loss scale to: 0.125
| WARNING: overflow detected, setting loss scale to: 0.0625
| epoch 025:     50 / 344 loss=3.463, nll_loss=1.439, ppl=2.71, wps=2276, ups=0, wpb=14224.681, bsz=48.000, num_updates=8289, lr=3.338e-05, gnorm=28.391, clip=1.000, oom=0.000, loss_scale=0.062, wall=40969, train_wall=1.11289e+06, article-summ      ary:loss=3.28534, article-summary:nll_loss=1.42316, article-summary:ntokens=4686.81, article-summary:nsentences=16, article-summary:sample_size=4686.81, gold_gen_byol:article:loss=0.178098, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9537.87, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 025:    100 / 344 loss=3.288, nll_loss=1.246, ppl=2.37, wps=2352, ups=0, wpb=14106.227, bsz=48.000, num_updates=8339, lr=3.33274e-05, gnorm=27.938, clip=1.000, oom=0.000, loss_scale=0.062, wall=41257, train_wall=1.11318e+06, article-su      mmary:loss=3.11822, article-summary:nll_loss=1.2387, article-summary:ntokens=4665.15, article-summary:nsentences=16, article-summary:sample_size=4665.15, gold_gen_byol:article:loss=0.170044, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9441.07, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 025:    150 / 344 loss=2.981, nll_loss=0.914, ppl=1.88, wps=2388, ups=0, wpb=14126.014, bsz=48.000, num_updates=8389, lr=3.32747e-05, gnorm=19.062, clip=1.000, oom=0.000, loss_scale=0.062, wall=41545, train_wall=1.11347e+06, article-su      mmary:loss=2.81611, article-summary:nll_loss=0.905563, article-summary:ntokens=4696.22, article-summary:nsentences=16, article-summary:sample_size=4696.22, gold_gen_byol:article:loss=0.164446, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9429.8, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 025:    200 / 344 loss=2.832, nll_loss=0.753, ppl=1.68, wps=2402, ups=0, wpb=14098.873, bsz=48.000, num_updates=8439, lr=3.32221e-05, gnorm=15.688, clip=1.000, oom=0.000, loss_scale=0.062, wall=41832, train_wall=1.11376e+06, article-su      mmary:loss=2.67151, article-summary:nll_loss=0.747112, article-summary:ntokens=4679.77, article-summary:nsentences=16, article-summary:sample_size=4679.77, gold_gen_byol:article:loss=0.160738, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9419.11, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 025:    250 / 344 loss=2.743, nll_loss=0.657, ppl=1.58, wps=2407, ups=0, wpb=14052.862, bsz=48.000, num_updates=8489, lr=3.31695e-05, gnorm=13.750, clip=1.000, oom=0.000, loss_scale=0.062, wall=42118, train_wall=1.11404e+06, article-su      mmary:loss=2.58506, article-summary:nll_loss=0.651825, article-summary:ntokens=4672.33, article-summary:nsentences=16, article-summary:sample_size=4672.33, gold_gen_byol:article:loss=0.157992, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9380.53, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 025:    300 / 344 loss=2.685, nll_loss=0.594, ppl=1.51, wps=2421, ups=0, wpb=14101.899, bsz=48.000, num_updates=8539, lr=3.31168e-05, gnorm=11.883, clip=1.000, oom=0.000, loss_scale=0.062, wall=42406, train_wall=1.11433e+06, article-su      mmary:loss=2.52909, article-summary:nll_loss=0.589562, article-summary:ntokens=4688.01, article-summary:nsentences=16, article-summary:sample_size=4688.01, gold_gen_byol:article:loss=0.15567, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9413.89, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 025 | loss 2.648 | nll_loss 0.555 | ppl 1.47 | wps 2420 | ups 0 | wpb 14038.962 | bsz 47.891 | num_updates 8582 | lr 3.30716e-05 | gnorm 10.617 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 42648 | train_wall 1.11457e+06 | article      -summary:loss 2.49401 | article-summary:nll_loss 0.550908 | article-summary:ntokens 4676.09 | article-summary:nsentences 15.9853 | article-summary:sample_size 4676.09 | gold_gen_byol:article:loss 0.154271 | gold_gen_byol:article:nll_loss 0 | g      old_gen_byol:article:ntokens 9390.49 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 025 | valid on 'valid' subset | loss 3.839 | nll_loss 2.120 | ppl 4.35 | num_updates 8582 | best_loss 3.35637 | article-summary:loss 3.80884 | article-summary:nll_loss 2.08759 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 25 @ 8582 updates) (writing took 8.024612426757812 seconds)
| epoch 026:     50 / 344 loss=2.374, nll_loss=0.265, ppl=1.2, wps=3089, ups=0, wpb=14013.157, bsz=48.000, num_updates=8633, lr=3.30179e-05, gnorm=1.343, clip=1.000, oom=0.000, loss_scale=0.062, wall=42893, train_wall=1.1148e+06, gold_gen_byol      :article:loss=0.140319, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9326.43, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.23403, article-summary:nll_loss=0.265629, articl      e-summary:ntokens=4686.73, article-summary:nsentences=16, article-summary:sample_size=4686.73
| epoch 026:    100 / 344 loss=2.374, nll_loss=0.268, ppl=1.2, wps=3105, ups=0, wpb=14085.505, bsz=48.000, num_updates=8683, lr=3.29653e-05, gnorm=1.485, clip=1.000, oom=0.000, loss_scale=0.062, wall=43120, train_wall=1.11503e+06, gold_gen_byo      l:article:loss=0.137961, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9388.59, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.23593, article-summary:nll_loss=0.267758, artic      le-summary:ntokens=4696.91, article-summary:nsentences=16, article-summary:sample_size=4696.91
| epoch 026:    150 / 344 loss=2.373, nll_loss=0.267, ppl=1.2, wps=3103, ups=0, wpb=14116.258, bsz=48.000, num_updates=8733, lr=3.29126e-05, gnorm=1.536, clip=1.000, oom=0.000, loss_scale=0.062, wall=43349, train_wall=1.11526e+06, gold_gen_byo      l:article:loss=0.137221, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9428.85, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.23552, article-summary:nll_loss=0.267256, artic      le-summary:ntokens=4687.41, article-summary:nsentences=16, article-summary:sample_size=4687.41
| epoch 026:    200 / 344 loss=2.371, nll_loss=0.268, ppl=1.2, wps=3112, ups=0, wpb=14128.965, bsz=48.000, num_updates=8783, lr=3.286e-05, gnorm=1.420, clip=1.000, oom=0.000, loss_scale=0.062, wall=43574, train_wall=1.11548e+06, gold_gen_byol:      article:loss=0.135153, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9441.91, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.23596, article-summary:nll_loss=0.267926, article      -summary:ntokens=4687.05, article-summary:nsentences=16, article-summary:sample_size=4687.05
| epoch 026:    250 / 344 loss=2.371, nll_loss=0.269, ppl=1.21, wps=3105, ups=0, wpb=14055.713, bsz=48.000, num_updates=8833, lr=3.28074e-05, gnorm=1.374, clip=1.000, oom=0.000, loss_scale=0.062, wall=43798, train_wall=1.11571e+06, gold_gen_by      ol:article:loss=0.13381, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9388.46, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.23681, article-summary:nll_loss=0.268885, artic      le-summary:ntokens=4667.25, article-summary:nsentences=16, article-summary:sample_size=4667.25
| epoch 026:    300 / 344 loss=2.377, nll_loss=0.276, ppl=1.21, wps=3118, ups=0, wpb=14145.040, bsz=48.000, num_updates=8883, lr=3.27547e-05, gnorm=1.468, clip=1.000, oom=0.000, loss_scale=0.062, wall=44027, train_wall=1.11594e+06, gold_gen_by      ol:article:loss=0.132229, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9456.45, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.24456, article-summary:nll_loss=0.276671, arti      cle-summary:ntokens=4688.59, article-summary:nsentences=16, article-summary:sample_size=4688.59
| epoch 026 | loss 2.374 | nll_loss 0.275 | ppl 1.21 | wps 3113 | ups 0 | wpb 14114.212 | bsz 47.985 | num_updates 8926 | lr 3.27095e-05 | gnorm 1.430 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 44221 | train_wall 1.11613e+06 | gold_gen      _byol:article:loss 0.131244 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9435.21 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.24261 | article-summary:nll_loss 0.274      902 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 026 | valid on 'valid' subset | loss 3.835 | nll_loss 2.098 | ppl 4.28 | num_updates 8926 | best_loss 3.35637 | article-summary:loss 3.80504 | article-summary:nll_loss 2.06601 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 26 @ 8926 updates) (writing took 7.012563705444336 seconds)
| epoch 027:     50 / 344 loss=2.350, nll_loss=0.259, ppl=1.2, wps=3123, ups=0, wpb=14192.412, bsz=48.000, num_updates=8977, lr=3.26558e-05, gnorm=1.201, clip=1.000, oom=0.000, loss_scale=0.062, wall=44466, train_wall=1.11636e+06, article-summ      ary:loss=2.22751, article-summary:nll_loss=0.258938, article-summary:ntokens=4712.33, article-summary:nsentences=16, article-summary:sample_size=4712.33, gold_gen_byol:article:loss=0.122681, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9480.08, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 027:    100 / 344 loss=2.346, nll_loss=0.256, ppl=1.19, wps=3101, ups=0, wpb=14105.624, bsz=48.000, num_updates=9027, lr=3.26032e-05, gnorm=1.247, clip=1.000, oom=0.000, loss_scale=0.062, wall=44693, train_wall=1.11659e+06, article-sum      mary:loss=2.22389, article-summary:nll_loss=0.256563, article-summary:ntokens=4667.96, article-summary:nsentences=16, article-summary:sample_size=4667.96, gold_gen_byol:article:loss=0.121853, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9437.66, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 027:    150 / 344 loss=2.346, nll_loss=0.258, ppl=1.2, wps=3114, ups=0, wpb=14237.861, bsz=48.000, num_updates=9077, lr=3.25505e-05, gnorm=1.490, clip=1.000, oom=0.000, loss_scale=0.062, wall=44924, train_wall=1.11682e+06, article-summ      ary:loss=2.22528, article-summary:nll_loss=0.257828, article-summary:ntokens=4699.85, article-summary:nsentences=16, article-summary:sample_size=4699.85, gold_gen_byol:article:loss=0.121208, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9538.01, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 027:    200 / 344 loss=2.347, nll_loss=0.259, ppl=1.2, wps=3112, ups=0, wpb=14208.776, bsz=48.000, num_updates=9127, lr=3.24979e-05, gnorm=1.422, clip=1.000, oom=0.000, loss_scale=0.062, wall=45152, train_wall=1.11704e+06, article-summ      ary:loss=2.22627, article-summary:nll_loss=0.258987, article-summary:ntokens=4699.26, article-summary:nsentences=16, article-summary:sample_size=4699.26, gold_gen_byol:article:loss=0.120453, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9509.51, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 027:    250 / 344 loss=2.347, nll_loss=0.260, ppl=1.2, wps=3116, ups=0, wpb=14204.904, bsz=48.000, num_updates=9177, lr=3.24453e-05, gnorm=1.402, clip=1.000, oom=0.000, loss_scale=0.062, wall=45378, train_wall=1.11727e+06, article-summ      ary:loss=2.22729, article-summary:nll_loss=0.260026, article-summary:ntokens=4698.85, article-summary:nsentences=16, article-summary:sample_size=4698.85, gold_gen_byol:article:loss=0.119975, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9506.06, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 027:    300 / 344 loss=2.346, nll_loss=0.260, ppl=1.2, wps=3109, ups=0, wpb=14150.186, bsz=48.000, num_updates=9227, lr=3.23926e-05, gnorm=1.351, clip=1.000, oom=0.000, loss_scale=0.062, wall=45604, train_wall=1.1175e+06, article-summa      ry:loss=2.22651, article-summary:nll_loss=0.259628, article-summary:ntokens=4688.07, article-summary:nsentences=16, article-summary:sample_size=4688.07, gold_gen_byol:article:loss=0.119772, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9462.11, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 027 | loss 2.346 | nll_loss 0.260 | ppl 1.2 | wps 3109 | ups 0 | wpb 14143.782 | bsz 47.985 | num_updates 9270 | lr 3.23474e-05 | gnorm 1.322 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 45799 | train_wall 1.11769e+06 | article-s      ummary:loss 2.22636 | article-summary:nll_loss 0.259748 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.119215 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9464.78 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 027 | valid on 'valid' subset | loss 3.856 | nll_loss 2.123 | ppl 4.36 | num_updates 9270 | best_loss 3.35637 | article-summary:loss 3.82713 | article-summary:nll_loss 2.09159 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 27 @ 9270 updates) (writing took 8.369996309280396 seconds)
| epoch 028:     50 / 344 loss=2.327, nll_loss=0.247, ppl=1.19, wps=3020, ups=0, wpb=13559.922, bsz=48.000, num_updates=9321, lr=3.22937e-05, gnorm=1.097, clip=1.000, oom=0.000, loss_scale=0.125, wall=46043, train_wall=1.11792e+06, article-sum      mary:loss=2.21276, article-summary:nll_loss=0.247326, article-summary:ntokens=4536.86, article-summary:nsentences=16, article-summary:sample_size=4536.86, gold_gen_byol:article:loss=0.11443, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9023.06, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 028:    100 / 344 loss=2.330, nll_loss=0.249, ppl=1.19, wps=3054, ups=0, wpb=13852.446, bsz=48.000, num_updates=9371, lr=3.22411e-05, gnorm=1.075, clip=1.000, oom=0.000, loss_scale=0.125, wall=46272, train_wall=1.11815e+06, article-sum      mary:loss=2.21515, article-summary:nll_loss=0.249367, article-summary:ntokens=4622.43, article-summary:nsentences=16, article-summary:sample_size=4622.43, gold_gen_byol:article:loss=0.114617, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9230.02, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 028:    150 / 344 loss=2.330, nll_loss=0.250, ppl=1.19, wps=3084, ups=0, wpb=14052.066, bsz=48.000, num_updates=9421, lr=3.21884e-05, gnorm=1.114, clip=1.000, oom=0.000, loss_scale=0.125, wall=46502, train_wall=1.11838e+06, article-sum      mary:loss=2.21518, article-summary:nll_loss=0.249897, article-summary:ntokens=4682.77, article-summary:nsentences=16, article-summary:sample_size=4682.77, gold_gen_byol:article:loss=0.114542, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9369.3, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 028:    200 / 344 loss=2.330, nll_loss=0.250, ppl=1.19, wps=3075, ups=0, wpb=13995.537, bsz=48.000, num_updates=9471, lr=3.21358e-05, gnorm=1.229, clip=1.000, oom=0.000, loss_scale=0.125, wall=46729, train_wall=1.11860e+06, article-sum      mary:loss=2.21565, article-summary:nll_loss=0.250207, article-summary:ntokens=4673.79, article-summary:nsentences=16, article-summary:sample_size=4673.79, gold_gen_byol:article:loss=0.113887, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9321.75, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 028:    250 / 344 loss=2.329, nll_loss=0.250, ppl=1.19, wps=3075, ups=0, wpb=14033.239, bsz=48.000, num_updates=9521, lr=3.20832e-05, gnorm=1.177, clip=1.000, oom=0.000, loss_scale=0.125, wall=46959, train_wall=1.11884e+06, article-sum      mary:loss=2.21517, article-summary:nll_loss=0.250197, article-summary:ntokens=4670.56, article-summary:nsentences=16, article-summary:sample_size=4670.56, gold_gen_byol:article:loss=0.1134, gold_gen_byol:article:nll_loss=0, gold_gen_byol:artic      le:ntokens=9362.68, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 028:    300 / 344 loss=2.329, nll_loss=0.250, ppl=1.19, wps=3084, ups=0, wpb=14065.266, bsz=48.000, num_updates=9571, lr=3.20305e-05, gnorm=1.339, clip=1.000, oom=0.000, loss_scale=0.125, wall=47187, train_wall=1.11906e+06, article-sum      mary:loss=2.21558, article-summary:nll_loss=0.250546, article-summary:ntokens=4681.24, article-summary:nsentences=16, article-summary:sample_size=4681.24, gold_gen_byol:article:loss=0.112938, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9384.03, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 028 | loss 2.328 | nll_loss 0.251 | ppl 1.19 | wps 3087 | ups 0 | wpb 14092.689 | bsz 47.962 | num_updates 9614 | lr 3.19853e-05 | gnorm 1.345 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 47384 | train_wall 1.11926e+06 | article-      summary:loss 2.2155 | article-summary:nll_loss 0.250581 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.112639 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9413.69 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 028 | valid on 'valid' subset | loss 3.854 | nll_loss 2.133 | ppl 4.39 | num_updates 9614 | best_loss 3.35637 | article-summary:loss 3.82453 | article-summary:nll_loss 2.10107 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 28 @ 9614 updates) (writing took 8.42805552482605 seconds)
| epoch 029:     50 / 344 loss=2.316, nll_loss=0.244, ppl=1.18, wps=2533, ups=0, wpb=14780.765, bsz=48.000, num_updates=9665, lr=3.19316e-05, gnorm=1.008, clip=1.000, oom=0.000, loss_scale=0.125, wall=47696, train_wall=1.11956e+06, article-sum      mary:loss=2.20774, article-summary:nll_loss=0.243868, article-summary:ntokens=4872.45, article-summary:nsentences=16, article-summary:sample_size=4872.45, gold_gen_byol:article:loss=0.107902, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9908.31, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 029:    100 / 344 loss=2.316, nll_loss=0.243, ppl=1.18, wps=2518, ups=0, wpb=14581.238, bsz=48.000, num_updates=9715, lr=3.18789e-05, gnorm=1.056, clip=1.000, oom=0.000, loss_scale=0.125, wall=47984, train_wall=1.11984e+06, article-sum      mary:loss=2.20783, article-summary:nll_loss=0.243309, article-summary:ntokens=4788.17, article-summary:nsentences=16, article-summary:sample_size=4788.17, gold_gen_byol:article:loss=0.107683, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9793.07, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 029:    150 / 344 loss=2.314, nll_loss=0.243, ppl=1.18, wps=2501, ups=0, wpb=14470.570, bsz=48.000, num_updates=9765, lr=3.18263e-05, gnorm=1.045, clip=1.000, oom=0.000, loss_scale=0.125, wall=48272, train_wall=1.12013e+06, article-sum      mary:loss=2.20685, article-summary:nll_loss=0.242683, article-summary:ntokens=4746.33, article-summary:nsentences=16, article-summary:sample_size=4746.33, gold_gen_byol:article:loss=0.107356, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9724.24, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 029:    200 / 344 loss=2.315, nll_loss=0.244, ppl=1.18, wps=2483, ups=0, wpb=14331.139, bsz=48.000, num_updates=9815, lr=3.17737e-05, gnorm=1.031, clip=1.000, oom=0.000, loss_scale=0.125, wall=48559, train_wall=1.12042e+06, article-sum      mary:loss=2.20776, article-summary:nll_loss=0.243786, article-summary:ntokens=4719.72, article-summary:nsentences=16, article-summary:sample_size=4719.72, gold_gen_byol:article:loss=0.107059, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9611.42, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 029:    250 / 344 loss=2.315, nll_loss=0.244, ppl=1.18, wps=2475, ups=0, wpb=14246.339, bsz=48.000, num_updates=9865, lr=3.17211e-05, gnorm=1.012, clip=1.000, oom=0.000, loss_scale=0.125, wall=48844, train_wall=1.1207e+06, article-summ      ary:loss=2.20824, article-summary:nll_loss=0.244364, article-summary:ntokens=4709.1, article-summary:nsentences=16, article-summary:sample_size=4709.1, gold_gen_byol:article:loss=0.106873, gold_gen_byol:article:nll_loss=0, gold_gen_byol:articl      e:ntokens=9537.24, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 029:    300 / 344 loss=2.315, nll_loss=0.245, ppl=1.18, wps=2468, ups=0, wpb=14180.950, bsz=48.000, num_updates=9915, lr=3.16684e-05, gnorm=1.007, clip=1.000, oom=0.000, loss_scale=0.125, wall=49128, train_wall=1.12099e+06, article-sum      mary:loss=2.20821, article-summary:nll_loss=0.244716, article-summary:ntokens=4692.03, article-summary:nsentences=16, article-summary:sample_size=4692.03, gold_gen_byol:article:loss=0.106751, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9488.92, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 029 | loss 2.315 | nll_loss 0.245 | ppl 1.19 | wps 2464 | ups 0 | wpb 14109.468 | bsz 47.892 | num_updates 9958 | lr 3.16232e-05 | gnorm 1.001 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 49369 | train_wall 1.12123e+06 | article-      summary:loss 2.20871 | article-summary:nll_loss 0.24519 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.106418 | gold_gen_byol:article:nll_loss 0 | gold_gen_      byol:article:ntokens 9457.96 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 029 | valid on 'valid' subset | loss 3.859 | nll_loss 2.130 | ppl 4.38 | num_updates 9958 | best_loss 3.35637 | article-summary:loss 3.82745 | article-summary:nll_loss 2.09604 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 29 @ 9958 updates) (writing took 8.355295181274414 seconds)
| epoch 030:     50 / 344 loss=2.304, nll_loss=0.237, ppl=1.18, wps=3067, ups=0, wpb=13567.510, bsz=48.000, num_updates=10009, lr=3.15695e-05, gnorm=1.877, clip=1.000, oom=0.000, loss_scale=0.125, wall=49609, train_wall=1.12145e+06, gold_gen_b      yol:article:loss=0.105127, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9047.14, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.19849, article-summary:nll_loss=0.23698, arti      cle-summary:ntokens=4520.37, article-summary:nsentences=16, article-summary:sample_size=4520.37
| epoch 030:    100 / 344 loss=2.304, nll_loss=0.238, ppl=1.18, wps=3077, ups=0, wpb=13765.614, bsz=48.000, num_updates=10059, lr=3.15168e-05, gnorm=1.466, clip=1.000, oom=0.000, loss_scale=0.125, wall=49835, train_wall=1.12168e+06, gold_gen_b      yol:article:loss=0.104523, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9181.23, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.19919, article-summary:nll_loss=0.238038, art      icle-summary:ntokens=4584.39, article-summary:nsentences=16, article-summary:sample_size=4584.39
| epoch 030:    150 / 344 loss=2.304, nll_loss=0.239, ppl=1.18, wps=3100, ups=0, wpb=13977.417, bsz=48.000, num_updates=10109, lr=3.14642e-05, gnorm=1.315, clip=1.000, oom=0.000, loss_scale=0.125, wall=50064, train_wall=1.12191e+06, gold_gen_b      yol:article:loss=0.104092, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9340.13, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.20032, article-summary:nll_loss=0.238867, art      icle-summary:ntokens=4637.28, article-summary:nsentences=16, article-summary:sample_size=4637.28
| epoch 030:    200 / 344 loss=2.307, nll_loss=0.241, ppl=1.18, wps=3118, ups=0, wpb=14079.821, bsz=48.000, num_updates=10159, lr=3.14116e-05, gnorm=1.271, clip=1.000, oom=0.000, loss_scale=0.125, wall=50291, train_wall=1.12214e+06, gold_gen_b      yol:article:loss=0.103622, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9415.48, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.20346, article-summary:nll_loss=0.241555, art      icle-summary:ntokens=4664.34, article-summary:nsentences=16, article-summary:sample_size=4664.34
| epoch 030:    250 / 344 loss=2.306, nll_loss=0.241, ppl=1.18, wps=3119, ups=0, wpb=14098.602, bsz=48.000, num_updates=10209, lr=3.13589e-05, gnorm=1.207, clip=1.000, oom=0.000, loss_scale=0.125, wall=50518, train_wall=1.12236e+06, gold_gen_b      yol:article:loss=0.103013, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9423.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.20258, article-summary:nll_loss=0.240935, art      icle-summary:ntokens=4674.67, article-summary:nsentences=16, article-summary:sample_size=4674.67
| epoch 030:    300 / 344 loss=2.306, nll_loss=0.241, ppl=1.18, wps=3130, ups=0, wpb=14172.764, bsz=48.000, num_updates=10259, lr=3.13063e-05, gnorm=1.162, clip=1.000, oom=0.000, loss_scale=0.125, wall=50746, train_wall=1.12259e+06, gold_gen_b      yol:article:loss=0.102621, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9477.79, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.20306, article-summary:nll_loss=0.241222, art      icle-summary:ntokens=4694.97, article-summary:nsentences=16, article-summary:sample_size=4694.97
| epoch 030 | loss 2.305 | nll_loss 0.241 | ppl 1.18 | wps 3127 | ups 0 | wpb 14122.270 | bsz 47.985 | num_updates 10302 | lr 3.12611e-05 | gnorm 1.128 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 50937 | train_wall 1.12278e+06 | gold_ge      n_byol:article:loss 0.102247 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9443.27 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.20249 | article-summary:nll_loss 0.24      1047 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 030 | valid on 'valid' subset | loss 3.884 | nll_loss 2.173 | ppl 4.51 | num_updates 10302 | best_loss 3.35637 | article-summary:loss 3.85255 | article-summary:nll_loss 2.13721 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 30 @ 10302 updates) (writing took 7.391658306121826 seconds)
| epoch 031:     50 / 344 loss=2.293, nll_loss=0.234, ppl=1.18, wps=3167, ups=0, wpb=14699.431, bsz=48.000, num_updates=10353, lr=3.12074e-05, gnorm=1.735, clip=1.000, oom=0.000, loss_scale=0.250, wall=51187, train_wall=1.12302e+06, article-su      mmary:loss=2.19548, article-summary:nll_loss=0.234506, article-summary:ntokens=4814.96, article-summary:nsentences=16, article-summary:sample_size=4814.96, gold_gen_byol:article:loss=0.0974889, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9884.47, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 031:    100 / 344 loss=2.296, nll_loss=0.236, ppl=1.18, wps=3113, ups=0, wpb=14237.327, bsz=48.000, num_updates=10403, lr=3.11547e-05, gnorm=1.608, clip=1.000, oom=0.000, loss_scale=0.250, wall=51412, train_wall=1.12324e+06, article-su      mmary:loss=2.1968, article-summary:nll_loss=0.236335, article-summary:ntokens=4706.67, article-summary:nsentences=16, article-summary:sample_size=4706.67, gold_gen_byol:article:loss=0.0988166, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9530.65, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 031:    150 / 344 loss=2.297, nll_loss=0.237, ppl=1.18, wps=3112, ups=0, wpb=14113.483, bsz=48.000, num_updates=10453, lr=3.11021e-05, gnorm=1.454, clip=1.000, oom=0.000, loss_scale=0.250, wall=51635, train_wall=1.12346e+06, article-su      mmary:loss=2.19696, article-summary:nll_loss=0.236643, article-summary:ntokens=4671.52, article-summary:nsentences=16, article-summary:sample_size=4671.52, gold_gen_byol:article:loss=0.0995874, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9441.96, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 031:    200 / 344 loss=2.297, nll_loss=0.237, ppl=1.18, wps=3100, ups=0, wpb=14028.542, bsz=48.000, num_updates=10503, lr=3.10495e-05, gnorm=1.342, clip=1.000, oom=0.000, loss_scale=0.250, wall=51859, train_wall=1.12369e+06, article-su      mmary:loss=2.1973, article-summary:nll_loss=0.236711, article-summary:ntokens=4663.91, article-summary:nsentences=16, article-summary:sample_size=4663.91, gold_gen_byol:article:loss=0.100075, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9364.64, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 031:    250 / 344 loss=2.297, nll_loss=0.237, ppl=1.18, wps=3105, ups=0, wpb=14063.466, bsz=48.000, num_updates=10553, lr=3.09968e-05, gnorm=1.342, clip=1.000, oom=0.000, loss_scale=0.250, wall=52087, train_wall=1.12392e+06, article-su      mmary:loss=2.197, article-summary:nll_loss=0.236606, article-summary:ntokens=4669.59, article-summary:nsentences=16, article-summary:sample_size=4669.59, gold_gen_byol:article:loss=0.100022, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9393.88, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 031:    300 / 344 loss=2.296, nll_loss=0.236, ppl=1.18, wps=3106, ups=0, wpb=14100.495, bsz=48.000, num_updates=10603, lr=3.09442e-05, gnorm=1.282, clip=1.000, oom=0.000, loss_scale=0.250, wall=52316, train_wall=1.12414e+06, article-su      mmary:loss=2.19599, article-summary:nll_loss=0.235935, article-summary:ntokens=4680.79, article-summary:nsentences=16, article-summary:sample_size=4680.79, gold_gen_byol:article:loss=0.100277, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9419.71, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 031 | loss 2.296 | nll_loss 0.236 | ppl 1.18 | wps 3104 | ups 0 | wpb 14101.189 | bsz 47.985 | num_updates 10646 | lr 3.08989e-05 | gnorm 1.265 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 52513 | train_wall 1.12434e+06 | article      -summary:loss 2.19591 | article-summary:nll_loss 0.236115 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.100391 | gold_gen_byol:article:nll_loss 0 | gold_ge      n_byol:article:ntokens 9422.19 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 031 | valid on 'valid' subset | loss 3.893 | nll_loss 2.186 | ppl 4.55 | num_updates 10646 | best_loss 3.35637 | article-summary:loss 3.86355 | article-summary:nll_loss 2.15237 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 31 @ 10646 updates) (writing took 8.339102029800415 seconds)
| WARNING: overflow detected, setting loss scale to: 0.125
| epoch 032:     50 / 344 loss=2.297, nll_loss=0.234, ppl=1.18, wps=2995, ups=0, wpb=13761.260, bsz=48.000, num_updates=10696, lr=3.08463e-05, gnorm=0.952, clip=1.000, oom=0.000, loss_scale=0.125, wall=52757, train_wall=1.12457e+06, article-su      mmary:loss=2.19446, article-summary:nll_loss=0.234231, article-summary:ntokens=4578.06, article-summary:nsentences=16, article-summary:sample_size=4578.06, gold_gen_byol:article:loss=0.10214, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9183.2, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 032:    100 / 344 loss=2.295, nll_loss=0.233, ppl=1.18, wps=3037, ups=0, wpb=14019.080, bsz=48.000, num_updates=10746, lr=3.07937e-05, gnorm=1.297, clip=1.000, oom=0.000, loss_scale=0.125, wall=52989, train_wall=1.1248e+06, article-sum      mary:loss=2.1929, article-summary:nll_loss=0.232898, article-summary:ntokens=4628.24, article-summary:nsentences=16, article-summary:sample_size=4628.24, gold_gen_byol:article:loss=0.101859, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9390.84, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 032:    150 / 344 loss=2.296, nll_loss=0.234, ppl=1.18, wps=3076, ups=0, wpb=14151.987, bsz=48.000, num_updates=10796, lr=3.07411e-05, gnorm=1.232, clip=1.000, oom=0.000, loss_scale=0.125, wall=53218, train_wall=1.12503e+06, article-su      mmary:loss=2.19416, article-summary:nll_loss=0.234397, article-summary:ntokens=4698.81, article-summary:nsentences=16, article-summary:sample_size=4698.81, gold_gen_byol:article:loss=0.101712, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9453.17, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 032:    200 / 344 loss=2.296, nll_loss=0.235, ppl=1.18, wps=3097, ups=0, wpb=14261.115, bsz=48.000, num_updates=10846, lr=3.06884e-05, gnorm=1.463, clip=1.000, oom=0.000, loss_scale=0.125, wall=53448, train_wall=1.12526e+06, article-su      mmary:loss=2.19442, article-summary:nll_loss=0.235115, article-summary:ntokens=4719.44, article-summary:nsentences=16, article-summary:sample_size=4719.44, gold_gen_byol:article:loss=0.101545, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9541.68, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 032:    250 / 344 loss=2.298, nll_loss=0.237, ppl=1.18, wps=3084, ups=0, wpb=14124.248, bsz=48.000, num_updates=10896, lr=3.06358e-05, gnorm=1.397, clip=1.000, oom=0.000, loss_scale=0.125, wall=53672, train_wall=1.12548e+06, article-su      mmary:loss=2.19598, article-summary:nll_loss=0.237264, article-summary:ntokens=4681, article-summary:nsentences=16, article-summary:sample_size=4681, gold_gen_byol:article:loss=0.101992, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:      ntokens=9443.25, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 032:    300 / 344 loss=2.298, nll_loss=0.237, ppl=1.18, wps=3089, ups=0, wpb=14138.543, bsz=48.000, num_updates=10946, lr=3.05832e-05, gnorm=1.385, clip=1.000, oom=0.000, loss_scale=0.125, wall=53901, train_wall=1.12571e+06, article-su      mmary:loss=2.19576, article-summary:nll_loss=0.236946, article-summary:ntokens=4684.76, article-summary:nsentences=16, article-summary:sample_size=4684.76, gold_gen_byol:article:loss=0.10231, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9453.79, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 032 | loss 2.298 | nll_loss 0.237 | ppl 1.18 | wps 3086 | ups 0 | wpb 14114.510 | bsz 47.962 | num_updates 10989 | lr 3.05379e-05 | gnorm 1.389 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 54096 | train_wall 1.12591e+06 | article      -summary:loss 2.19587 | article-summary:nll_loss 0.237457 | article-summary:ntokens 4678.94 | article-summary:nsentences 15.9854 | article-summary:sample_size 4678.94 | gold_gen_byol:article:loss 0.10242 | gold_gen_byol:article:nll_loss 0 | go      ld_gen_byol:article:ntokens 9435.57 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 032 | valid on 'valid' subset | loss 3.886 | nll_loss 2.175 | ppl 4.52 | num_updates 10989 | best_loss 3.35637 | article-summary:loss 3.85636 | article-summary:nll_loss 2.14229 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 32 @ 10989 updates) (writing took 7.8000476360321045 seconds)
| epoch 033:     50 / 344 loss=2.291, nll_loss=0.230, ppl=1.17, wps=2472, ups=0, wpb=14387.000, bsz=48.000, num_updates=11040, lr=3.04842e-05, gnorm=1.139, clip=1.000, oom=0.000, loss_scale=0.125, wall=54406, train_wall=1.1262e+06, article-sum      mary:loss=2.18814, article-summary:nll_loss=0.229501, article-summary:ntokens=4783, article-summary:nsentences=16, article-summary:sample_size=4783, gold_gen_byol:article:loss=0.102413, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:n      tokens=9604, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 033:    100 / 344 loss=2.289, nll_loss=0.229, ppl=1.17, wps=2465, ups=0, wpb=14205.604, bsz=48.000, num_updates=11090, lr=3.04316e-05, gnorm=1.047, clip=1.000, oom=0.000, loss_scale=0.125, wall=54692, train_wall=1.12649e+06, article-su      mmary:loss=2.18726, article-summary:nll_loss=0.2293, article-summary:ntokens=4753.56, article-summary:nsentences=16, article-summary:sample_size=4753.56, gold_gen_byol:article:loss=0.102152, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9452.04, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 033:    150 / 344 loss=2.289, nll_loss=0.230, ppl=1.17, wps=2456, ups=0, wpb=14119.656, bsz=48.000, num_updates=11140, lr=3.03789e-05, gnorm=1.000, clip=1.000, oom=0.000, loss_scale=0.125, wall=54977, train_wall=1.12678e+06, article-su      mmary:loss=2.18706, article-summary:nll_loss=0.229408, article-summary:ntokens=4710.28, article-summary:nsentences=16, article-summary:sample_size=4710.28, gold_gen_byol:article:loss=0.102215, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9409.38, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 033:    200 / 344 loss=2.292, nll_loss=0.232, ppl=1.17, wps=2447, ups=0, wpb=14060.662, bsz=48.000, num_updates=11190, lr=3.03263e-05, gnorm=1.132, clip=1.000, oom=0.000, loss_scale=0.125, wall=55264, train_wall=1.12706e+06, article-su      mmary:loss=2.18959, article-summary:nll_loss=0.231636, article-summary:ntokens=4675.15, article-summary:nsentences=16, article-summary:sample_size=4675.15, gold_gen_byol:article:loss=0.102259, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9385.51, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 033:    250 / 344 loss=2.294, nll_loss=0.234, ppl=1.18, wps=2456, ups=0, wpb=14104.072, bsz=48.000, num_updates=11240, lr=3.02737e-05, gnorm=1.174, clip=1.000, oom=0.000, loss_scale=0.125, wall=55551, train_wall=1.12735e+06, article-su      mmary:loss=2.19147, article-summary:nll_loss=0.233528, article-summary:ntokens=4683.1, article-summary:nsentences=16, article-summary:sample_size=4683.1, gold_gen_byol:article:loss=0.102426, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9420.97, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 033:    300 / 344 loss=2.294, nll_loss=0.234, ppl=1.18, wps=2452, ups=0, wpb=14052.080, bsz=48.000, num_updates=11290, lr=3.02211e-05, gnorm=1.187, clip=1.000, oom=0.000, loss_scale=0.125, wall=55835, train_wall=1.12763e+06, article-su      mmary:loss=2.1916, article-summary:nll_loss=0.234044, article-summary:ntokens=4673.22, article-summary:nsentences=16, article-summary:sample_size=4673.22, gold_gen_byol:article:loss=0.102751, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9378.86, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 033 | loss 2.295 | nll_loss 0.235 | ppl 1.18 | wps 2457 | ups 0 | wpb 14056.956 | bsz 47.892 | num_updates 11333 | lr 3.01758e-05 | gnorm 1.345 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 56078 | train_wall 1.12787e+06 | article      -summary:loss 2.19207 | article-summary:nll_loss 0.234553 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.102723 | gold_gen_byol:article:nll_loss 0 | gold_ge      n_byol:article:ntokens 9405.29 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 033 | valid on 'valid' subset | loss 3.899 | nll_loss 2.197 | ppl 4.59 | num_updates 11333 | best_loss 3.35637 | article-summary:loss 3.86957 | article-summary:nll_loss 2.16377 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 33 @ 11333 updates) (writing took 7.9622955322265625 seconds)
| epoch 034:     50 / 344 loss=2.285, nll_loss=0.225, ppl=1.17, wps=3115, ups=0, wpb=14222.549, bsz=48.000, num_updates=11384, lr=3.01221e-05, gnorm=0.875, clip=1.000, oom=0.000, loss_scale=0.125, wall=56325, train_wall=1.12811e+06, gold_gen_b      yol:article:loss=0.102526, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9525.49, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.18261, article-summary:nll_loss=0.225861, art      icle-summary:ntokens=4697.06, article-summary:nsentences=16, article-summary:sample_size=4697.06
| epoch 034:    100 / 344 loss=2.285, nll_loss=0.225, ppl=1.17, wps=3124, ups=0, wpb=14178.515, bsz=48.000, num_updates=11434, lr=3.00695e-05, gnorm=0.953, clip=1.000, oom=0.000, loss_scale=0.125, wall=56550, train_wall=1.12833e+06, gold_gen_b      yol:article:loss=0.102671, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9504.04, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.18267, article-summary:nll_loss=0.225728, art      icle-summary:ntokens=4674.48, article-summary:nsentences=16, article-summary:sample_size=4674.48
| epoch 034:    150 / 344 loss=2.285, nll_loss=0.226, ppl=1.17, wps=3126, ups=0, wpb=14176.152, bsz=48.000, num_updates=11484, lr=3.00168e-05, gnorm=0.925, clip=1.000, oom=0.000, loss_scale=0.125, wall=56777, train_wall=1.12856e+06, gold_gen_b      yol:article:loss=0.102105, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9487.26, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.18292, article-summary:nll_loss=0.225944, art      icle-summary:ntokens=4688.89, article-summary:nsentences=16, article-summary:sample_size=4688.89
| epoch 034:    200 / 344 loss=2.285, nll_loss=0.226, ppl=1.17, wps=3119, ups=0, wpb=14150.572, bsz=48.000, num_updates=11534, lr=2.99642e-05, gnorm=0.932, clip=1.000, oom=0.000, loss_scale=0.125, wall=57004, train_wall=1.12878e+06, gold_gen_b      yol:article:loss=0.101857, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9470.91, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.18281, article-summary:nll_loss=0.226154, art      icle-summary:ntokens=4679.67, article-summary:nsentences=16, article-summary:sample_size=4679.67
| epoch 034:    250 / 344 loss=2.285, nll_loss=0.227, ppl=1.17, wps=3118, ups=0, wpb=14097.972, bsz=48.000, num_updates=11584, lr=2.99116e-05, gnorm=0.946, clip=1.000, oom=0.000, loss_scale=0.125, wall=57227, train_wall=1.12901e+06, gold_gen_b      yol:article:loss=0.101373, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9430.45, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.18362, article-summary:nll_loss=0.2268, artic      le-summary:ntokens=4667.52, article-summary:nsentences=16, article-summary:sample_size=4667.52
| epoch 034:    300 / 344 loss=2.285, nll_loss=0.227, ppl=1.17, wps=3115, ups=0, wpb=14056.804, bsz=48.000, num_updates=11634, lr=2.98589e-05, gnorm=0.943, clip=1.000, oom=0.000, loss_scale=0.125, wall=57450, train_wall=1.12923e+06, gold_gen_b      yol:article:loss=0.101028, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9399.46, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.18366, article-summary:nll_loss=0.226882, art      icle-summary:ntokens=4657.35, article-summary:nsentences=16, article-summary:sample_size=4657.35
| epoch 034 | loss 2.284 | nll_loss 0.227 | ppl 1.17 | wps 3130 | ups 0 | wpb 14142.224 | bsz 47.985 | num_updates 11677 | lr 2.98137e-05 | gnorm 0.948 | clip 1.000 | oom 0.000 | loss_scale 0.125 | wall 57646 | train_wall 1.12943e+06 | gold_ge      n_byol:article:loss 0.100736 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9463.22 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.18356 | article-summary:nll_loss 0.22      688 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 034 | valid on 'valid' subset | loss 3.924 | nll_loss 2.230 | ppl 4.69 | num_updates 11677 | best_loss 3.35637 | article-summary:loss 3.89354 | article-summary:nll_loss 2.19613 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 34 @ 11677 updates) (writing took 7.688847303390503 seconds)
| epoch 035:     50 / 344 loss=2.276, nll_loss=0.222, ppl=1.17, wps=3098, ups=0, wpb=14076.118, bsz=48.000, num_updates=11728, lr=2.976e-05, gnorm=1.115, clip=1.000, oom=0.000, loss_scale=0.250, wall=57891, train_wall=1.12966e+06, article-summ      ary:loss=2.17772, article-summary:nll_loss=0.222247, article-summary:ntokens=4713.76, article-summary:nsentences=16, article-summary:sample_size=4713.76, gold_gen_byol:article:loss=0.0980657, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9362.35, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 035:    100 / 344 loss=2.275, nll_loss=0.222, ppl=1.17, wps=3095, ups=0, wpb=13969.277, bsz=48.000, num_updates=11778, lr=2.97074e-05, gnorm=1.038, clip=1.000, oom=0.000, loss_scale=0.250, wall=58115, train_wall=1.12988e+06, article-su      mmary:loss=2.1779, article-summary:nll_loss=0.222396, article-summary:ntokens=4664.56, article-summary:nsentences=16, article-summary:sample_size=4664.56, gold_gen_byol:article:loss=0.0972724, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9304.71, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 035:    150 / 344 loss=2.276, nll_loss=0.223, ppl=1.17, wps=3082, ups=0, wpb=13886.272, bsz=48.000, num_updates=11828, lr=2.96547e-05, gnorm=1.002, clip=1.000, oom=0.000, loss_scale=0.250, wall=58340, train_wall=1.13011e+06, article-su      mmary:loss=2.17847, article-summary:nll_loss=0.223007, article-summary:ntokens=4640.58, article-summary:nsentences=16, article-summary:sample_size=4640.58, gold_gen_byol:article:loss=0.0970559, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9245.7, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 035:    200 / 344 loss=2.275, nll_loss=0.223, ppl=1.17, wps=3090, ups=0, wpb=13993.692, bsz=48.000, num_updates=11878, lr=2.96021e-05, gnorm=0.969, clip=1.000, oom=0.000, loss_scale=0.250, wall=58570, train_wall=1.13034e+06, article-su      mmary:loss=2.1787, article-summary:nll_loss=0.22316, article-summary:ntokens=4650.47, article-summary:nsentences=16, article-summary:sample_size=4650.47, gold_gen_byol:article:loss=0.0967976, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9343.22, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 035:    250 / 344 loss=2.275, nll_loss=0.223, ppl=1.17, wps=3104, ups=0, wpb=14114.522, bsz=48.000, num_updates=11928, lr=2.95495e-05, gnorm=0.938, clip=1.000, oom=0.000, loss_scale=0.250, wall=58801, train_wall=1.13057e+06, article-su      mmary:loss=2.17842, article-summary:nll_loss=0.222893, article-summary:ntokens=4675.16, article-summary:nsentences=16, article-summary:sample_size=4675.16, gold_gen_byol:article:loss=0.0962822, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9439.36, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 035:    300 / 344 loss=2.274, nll_loss=0.223, ppl=1.17, wps=3106, ups=0, wpb=14112.017, bsz=48.000, num_updates=11978, lr=2.94968e-05, gnorm=0.927, clip=1.000, oom=0.000, loss_scale=0.250, wall=59027, train_wall=1.13079e+06, article-su      mmary:loss=2.17814, article-summary:nll_loss=0.222759, article-summary:ntokens=4673.89, article-summary:nsentences=16, article-summary:sample_size=4673.89, gold_gen_byol:article:loss=0.0961444, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9438.13, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 035 | loss 2.275 | nll_loss 0.223 | ppl 1.17 | wps 3111 | ups 0 | wpb 14112.561 | bsz 47.985 | num_updates 12021 | lr 2.94516e-05 | gnorm 0.919 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 59220 | train_wall 1.13098e+06 | article      -summary:loss 2.17876 | article-summary:nll_loss 0.223201 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.0959608 | gold_gen_byol:article:nll_loss 0 | gold_g      en_byol:article:ntokens 9433.56 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 035 | valid on 'valid' subset | loss 3.922 | nll_loss 2.226 | ppl 4.68 | num_updates 12021 | best_loss 3.35637 | article-summary:loss 3.89485 | article-summary:nll_loss 2.19619 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 35 @ 12021 updates) (writing took 8.055801153182983 seconds)
| epoch 036:     50 / 344 loss=2.265, nll_loss=0.217, ppl=1.16, wps=3114, ups=0, wpb=14072.725, bsz=48.000, num_updates=12072, lr=2.93979e-05, gnorm=0.829, clip=1.000, oom=0.000, loss_scale=0.250, wall=59465, train_wall=1.13122e+06, article-su      mmary:loss=2.17103, article-summary:nll_loss=0.217415, article-summary:ntokens=4675.78, article-summary:nsentences=16, article-summary:sample_size=4675.78, gold_gen_byol:article:loss=0.0939543, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9396.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 036:    100 / 344 loss=2.266, nll_loss=0.218, ppl=1.16, wps=3088, ups=0, wpb=14052.416, bsz=48.000, num_updates=12122, lr=2.93453e-05, gnorm=0.899, clip=1.000, oom=0.000, loss_scale=0.250, wall=59694, train_wall=1.13144e+06, article-su      mmary:loss=2.17212, article-summary:nll_loss=0.218395, article-summary:ntokens=4690.59, article-summary:nsentences=16, article-summary:sample_size=4690.59, gold_gen_byol:article:loss=0.0936675, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9361.82, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 036:    150 / 344 loss=2.268, nll_loss=0.220, ppl=1.16, wps=3116, ups=0, wpb=14261.656, bsz=48.000, num_updates=12172, lr=2.92926e-05, gnorm=0.878, clip=1.000, oom=0.000, loss_scale=0.250, wall=59926, train_wall=1.13168e+06, article-su      mmary:loss=2.17416, article-summary:nll_loss=0.219663, article-summary:ntokens=4702.21, article-summary:nsentences=16, article-summary:sample_size=4702.21, gold_gen_byol:article:loss=0.0934606, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9559.44, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 036:    200 / 344 loss=2.268, nll_loss=0.220, ppl=1.16, wps=3118, ups=0, wpb=14288.930, bsz=48.000, num_updates=12222, lr=2.924e-05, gnorm=0.868, clip=1.000, oom=0.000, loss_scale=0.250, wall=60156, train_wall=1.13191e+06, article-summ      ary:loss=2.17456, article-summary:nll_loss=0.220036, article-summary:ntokens=4717.67, article-summary:nsentences=16, article-summary:sample_size=4717.67, gold_gen_byol:article:loss=0.0932752, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9571.26, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 036:    250 / 344 loss=2.268, nll_loss=0.220, ppl=1.16, wps=3106, ups=0, wpb=14182.426, bsz=48.000, num_updates=12272, lr=2.91874e-05, gnorm=0.886, clip=1.000, oom=0.000, loss_scale=0.250, wall=60381, train_wall=1.13213e+06, article-su      mmary:loss=2.17453, article-summary:nll_loss=0.220071, article-summary:ntokens=4692, article-summary:nsentences=16, article-summary:sample_size=4692, gold_gen_byol:article:loss=0.0929925, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article      :ntokens=9490.42, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 036:    300 / 344 loss=2.267, nll_loss=0.220, ppl=1.16, wps=3107, ups=0, wpb=14166.654, bsz=48.000, num_updates=12322, lr=2.91347e-05, gnorm=0.882, clip=1.000, oom=0.000, loss_scale=0.250, wall=60607, train_wall=1.13236e+06, article-su      mmary:loss=2.17487, article-summary:nll_loss=0.220347, article-summary:ntokens=4699.82, article-summary:nsentences=16, article-summary:sample_size=4699.82, gold_gen_byol:article:loss=0.0926252, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9466.83, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 036 | loss 2.267 | nll_loss 0.220 | ppl 1.16 | wps 3093 | ups 0 | wpb 14093.782 | bsz 47.962 | num_updates 12365 | lr 2.90895e-05 | gnorm 0.899 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 60802 | train_wall 1.13255e+06 | article      -summary:loss 2.17463 | article-summary:nll_loss 0.22038 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.0925075 | gold_gen_byol:article:nll_loss 0 | gold_ge      n_byol:article:ntokens 9414.78 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 036 | valid on 'valid' subset | loss 3.937 | nll_loss 2.249 | ppl 4.75 | num_updates 12365 | best_loss 3.35637 | article-summary:loss 3.90737 | article-summary:nll_loss 2.21527 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 36 @ 12365 updates) (writing took 8.233256816864014 seconds)
| epoch 037:     50 / 344 loss=2.258, nll_loss=0.214, ppl=1.16, wps=2464, ups=0, wpb=14401.745, bsz=48.000, num_updates=12416, lr=2.90358e-05, gnorm=0.797, clip=1.000, oom=0.000, loss_scale=0.250, wall=61113, train_wall=1.13285e+06, article-su      mmary:loss=2.16816, article-summary:nll_loss=0.213803, article-summary:ntokens=4742.22, article-summary:nsentences=16, article-summary:sample_size=4742.22, gold_gen_byol:article:loss=0.0899808, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9659.53, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 037:    100 / 344 loss=2.258, nll_loss=0.215, ppl=1.16, wps=2460, ups=0, wpb=14241.911, bsz=48.000, num_updates=12466, lr=2.89832e-05, gnorm=0.794, clip=1.000, oom=0.000, loss_scale=0.250, wall=61399, train_wall=1.13313e+06, article-su      mmary:loss=2.16814, article-summary:nll_loss=0.214788, article-summary:ntokens=4697.55, article-summary:nsentences=16, article-summary:sample_size=4697.55, gold_gen_byol:article:loss=0.0899016, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9544.36, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 037:    150 / 344 loss=2.259, nll_loss=0.216, ppl=1.16, wps=2461, ups=0, wpb=14175.530, bsz=48.000, num_updates=12516, lr=2.89305e-05, gnorm=0.795, clip=1.000, oom=0.000, loss_scale=0.250, wall=61684, train_wall=1.13342e+06, article-su      mmary:loss=2.16934, article-summary:nll_loss=0.215831, article-summary:ntokens=4688.22, article-summary:nsentences=16, article-summary:sample_size=4688.22, gold_gen_byol:article:loss=0.0901272, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9487.31, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 037:    200 / 344 loss=2.259, nll_loss=0.216, ppl=1.16, wps=2465, ups=0, wpb=14141.587, bsz=48.000, num_updates=12566, lr=2.88779e-05, gnorm=0.796, clip=1.000, oom=0.000, loss_scale=0.250, wall=61968, train_wall=1.1337e+06, article-sum      mary:loss=2.169, article-summary:nll_loss=0.215842, article-summary:ntokens=4681.65, article-summary:nsentences=16, article-summary:sample_size=4681.65, gold_gen_byol:article:loss=0.0900976, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9459.94, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 037:    250 / 344 loss=2.260, nll_loss=0.217, ppl=1.16, wps=2466, ups=0, wpb=14172.801, bsz=48.000, num_updates=12616, lr=2.88253e-05, gnorm=0.801, clip=1.000, oom=0.000, loss_scale=0.250, wall=62257, train_wall=1.13399e+06, article-su      mmary:loss=2.16992, article-summary:nll_loss=0.216544, article-summary:ntokens=4687.14, article-summary:nsentences=16, article-summary:sample_size=4687.14, gold_gen_byol:article:loss=0.0901768, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9485.66, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 037:    300 / 344 loss=2.260, nll_loss=0.217, ppl=1.16, wps=2465, ups=0, wpb=14192.106, bsz=48.000, num_updates=12666, lr=2.87726e-05, gnorm=0.809, clip=1.000, oom=0.000, loss_scale=0.250, wall=62548, train_wall=1.13428e+06, article-su      mmary:loss=2.17039, article-summary:nll_loss=0.21692, article-summary:ntokens=4684.64, article-summary:nsentences=16, article-summary:sample_size=4684.64, gold_gen_byol:article:loss=0.0899476, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9507.47, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 037 | loss 2.260 | nll_loss 0.217 | ppl 1.16 | wps 2464 | ups 0 | wpb 14129.328 | bsz 47.892 | num_updates 12709 | lr 2.87274e-05 | gnorm 0.810 | clip 1.000 | oom 0.000 | loss_scale 0.250 | wall 62787 | train_wall 1.13452e+06 | article      -summary:loss 2.17032 | article-summary:nll_loss 0.217036 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.0898226 | gold_gen_byol:article:nll_loss 0 | gold_g      en_byol:article:ntokens 9477.88 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 037 | valid on 'valid' subset | loss 3.929 | nll_loss 2.226 | ppl 4.68 | num_updates 12709 | best_loss 3.35637 | article-summary:loss 3.90282 | article-summary:nll_loss 2.19705 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 37 @ 12709 updates) (writing took 7.315530061721802 seconds)
| epoch 038:     50 / 344 loss=2.252, nll_loss=0.211, ppl=1.16, wps=3138, ups=0, wpb=14154.902, bsz=48.000, num_updates=12760, lr=2.86737e-05, gnorm=0.794, clip=1.000, oom=0.000, loss_scale=0.500, wall=63030, train_wall=1.13475e+06, gold_gen_b      yol:article:loss=0.088918, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9445.1, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.16317, article-summary:nll_loss=0.211886, arti      cle-summary:ntokens=4709.8, article-summary:nsentences=16, article-summary:sample_size=4709.8
| epoch 038:    100 / 344 loss=2.256, nll_loss=0.214, ppl=1.16, wps=3136, ups=0, wpb=14281.535, bsz=48.000, num_updates=12810, lr=2.86211e-05, gnorm=0.781, clip=1.000, oom=0.000, loss_scale=0.500, wall=63260, train_wall=1.13498e+06, gold_gen_b      yol:article:loss=0.0888484, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9521.15, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.16761, article-summary:nll_loss=0.214297, ar      ticle-summary:ntokens=4760.39, article-summary:nsentences=16, article-summary:sample_size=4760.39
| epoch 038:    150 / 344 loss=2.256, nll_loss=0.214, ppl=1.16, wps=3118, ups=0, wpb=14085.338, bsz=48.000, num_updates=12860, lr=2.85684e-05, gnorm=0.783, clip=1.000, oom=0.000, loss_scale=0.500, wall=63482, train_wall=1.1352e+06, gold_gen_by      ol:article:loss=0.0889647, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9401.67, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.16666, article-summary:nll_loss=0.213905, art      icle-summary:ntokens=4683.67, article-summary:nsentences=16, article-summary:sample_size=4683.67
| epoch 038:    200 / 344 loss=2.255, nll_loss=0.214, ppl=1.16, wps=3102, ups=0, wpb=14109.478, bsz=48.000, num_updates=12910, lr=2.85158e-05, gnorm=0.782, clip=1.000, oom=0.000, loss_scale=0.500, wall=63714, train_wall=1.13543e+06, gold_gen_b      yol:article:loss=0.088792, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9422.23, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.16632, article-summary:nll_loss=0.213893, art      icle-summary:ntokens=4687.25, article-summary:nsentences=16, article-summary:sample_size=4687.25
| epoch 038:    250 / 344 loss=2.255, nll_loss=0.214, ppl=1.16, wps=3096, ups=0, wpb=14083.685, bsz=48.000, num_updates=12960, lr=2.84632e-05, gnorm=0.785, clip=1.000, oom=0.000, loss_scale=0.500, wall=63942, train_wall=1.13566e+06, gold_gen_b      yol:article:loss=0.0886595, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9409.21, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.16656, article-summary:nll_loss=0.214216, ar      ticle-summary:ntokens=4674.47, article-summary:nsentences=16, article-summary:sample_size=4674.47
| epoch 038:    300 / 344 loss=2.255, nll_loss=0.214, ppl=1.16, wps=3104, ups=0, wpb=14102.409, bsz=48.000, num_updates=13010, lr=2.84105e-05, gnorm=0.826, clip=1.000, oom=0.000, loss_scale=0.500, wall=64167, train_wall=1.13588e+06, gold_gen_b      yol:article:loss=0.0883699, gold_gen_byol:article:nll_loss=0, gold_gen_byol:article:ntokens=9422.68, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32, article-summary:loss=2.16634, article-summary:nll_loss=0.214156, ar      ticle-summary:ntokens=4679.72, article-summary:nsentences=16, article-summary:sample_size=4679.72
| epoch 038 | loss 2.254 | nll_loss 0.214 | ppl 1.16 | wps 3107 | ups 0 | wpb 14105.898 | bsz 47.985 | num_updates 13053 | lr 2.83653e-05 | gnorm 0.822 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 64362 | train_wall 1.13608e+06 | gold_ge      n_byol:article:loss 0.0882111 | gold_gen_byol:article:nll_loss 0 | gold_gen_byol:article:ntokens 9426.9 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32 | article-summary:loss 2.16627 | article-summary:nll_loss 0.21      4247 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679
| epoch 038 | valid on 'valid' subset | loss 3.956 | nll_loss 2.268 | ppl 4.82 | num_updates 13053 | best_loss 3.35637 | article-summary:loss 3.93236 | article-summary:nll_loss 2.24052 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 38 @ 13053 updates) (writing took 7.166453123092651 seconds)
| epoch 039:     50 / 344 loss=2.250, nll_loss=0.211, ppl=1.16, wps=3169, ups=0, wpb=14433.255, bsz=48.000, num_updates=13104, lr=2.83116e-05, gnorm=0.770, clip=1.000, oom=0.000, loss_scale=0.500, wall=64608, train_wall=1.13631e+06, article-su      mmary:loss=2.16298, article-summary:nll_loss=0.211305, article-summary:ntokens=4746.27, article-summary:nsentences=16, article-summary:sample_size=4746.27, gold_gen_byol:article:loss=0.0865461, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9686.98, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 039:    100 / 344 loss=2.250, nll_loss=0.212, ppl=1.16, wps=3147, ups=0, wpb=14329.693, bsz=48.000, num_updates=13154, lr=2.82589e-05, gnorm=0.771, clip=1.000, oom=0.000, loss_scale=0.500, wall=64835, train_wall=1.13654e+06, article-su      mmary:loss=2.16385, article-summary:nll_loss=0.211741, article-summary:ntokens=4750.76, article-summary:nsentences=16, article-summary:sample_size=4750.76, gold_gen_byol:article:loss=0.0861859, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9578.93, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 039:    150 / 344 loss=2.250, nll_loss=0.212, ppl=1.16, wps=3165, ups=0, wpb=14474.907, bsz=48.000, num_updates=13204, lr=2.82063e-05, gnorm=0.769, clip=1.000, oom=0.000, loss_scale=0.500, wall=65066, train_wall=1.13677e+06, article-su      mmary:loss=2.16391, article-summary:nll_loss=0.212073, article-summary:ntokens=4800.31, article-summary:nsentences=16, article-summary:sample_size=4800.31, gold_gen_byol:article:loss=0.0859588, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9674.6, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 039:    200 / 344 loss=2.249, nll_loss=0.212, ppl=1.16, wps=3140, ups=0, wpb=14352.383, bsz=48.000, num_updates=13254, lr=2.81537e-05, gnorm=0.778, clip=1.000, oom=0.000, loss_scale=0.500, wall=65294, train_wall=1.137e+06, article-summ      ary:loss=2.16312, article-summary:nll_loss=0.211676, article-summary:ntokens=4757.56, article-summary:nsentences=16, article-summary:sample_size=4757.56, gold_gen_byol:article:loss=0.0859348, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9594.83, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 039:    250 / 344 loss=2.249, nll_loss=0.212, ppl=1.16, wps=3117, ups=0, wpb=14189.833, bsz=48.000, num_updates=13304, lr=2.81011e-05, gnorm=0.780, clip=1.000, oom=0.000, loss_scale=0.500, wall=65518, train_wall=1.13722e+06, article-su      mmary:loss=2.16312, article-summary:nll_loss=0.211877, article-summary:ntokens=4708.25, article-summary:nsentences=16, article-summary:sample_size=4708.25, gold_gen_byol:article:loss=0.0859796, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9481.58, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 039:    300 / 344 loss=2.249, nll_loss=0.212, ppl=1.16, wps=3115, ups=0, wpb=14167.179, bsz=48.000, num_updates=13354, lr=2.80484e-05, gnorm=0.778, clip=1.000, oom=0.000, loss_scale=0.500, wall=65744, train_wall=1.13745e+06, article-su      mmary:loss=2.16305, article-summary:nll_loss=0.211808, article-summary:ntokens=4696.76, article-summary:nsentences=16, article-summary:sample_size=4696.76, gold_gen_byol:article:loss=0.0857377, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9470.42, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 039 | loss 2.249 | nll_loss 0.212 | ppl 1.16 | wps 3104 | ups 0 | wpb 14115.922 | bsz 47.985 | num_updates 13397 | lr 2.80032e-05 | gnorm 0.783 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 65940 | train_wall 1.13764e+06 | article      -summary:loss 2.1632 | article-summary:nll_loss 0.212013 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.0856886 | gold_gen_byol:article:nll_loss 0 | gold_ge      n_byol:article:ntokens 9436.92 | gold_gen_byol:article:nsentences 32 | gold_gen_byol:article:sample_size 32
| epoch 039 | valid on 'valid' subset | loss 3.955 | nll_loss 2.270 | ppl 4.82 | num_updates 13397 | best_loss 3.35637 | article-summary:loss 3.9267 | article-summary:nll_loss 2.23889 | article-summary:ntokens 1140.18 | article-summary:nsenten      ces 3.98333 | article-summary:sample_size 1140.18
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 39 @ 13397 updates) (writing took 7.813718318939209 seconds)
| epoch 040:     50 / 344 loss=2.243, nll_loss=0.207, ppl=1.15, wps=3089, ups=0, wpb=14282.941, bsz=48.000, num_updates=13448, lr=2.79495e-05, gnorm=0.771, clip=1.000, oom=0.000, loss_scale=0.500, wall=66189, train_wall=1.13788e+06, article-su      mmary:loss=2.15745, article-summary:nll_loss=0.20732, article-summary:ntokens=4688.9, article-summary:nsentences=16, article-summary:sample_size=4688.9, gold_gen_byol:article:loss=0.0857127, gold_gen_byol:article:nll_loss=0, gold_gen_byol:arti      cle:ntokens=9594.04, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 040:    100 / 344 loss=2.244, nll_loss=0.209, ppl=1.16, wps=3127, ups=0, wpb=14463.653, bsz=48.000, num_updates=13498, lr=2.78968e-05, gnorm=0.754, clip=1.000, oom=0.000, loss_scale=0.500, wall=66420, train_wall=1.13811e+06, article-su      mmary:loss=2.1594, article-summary:nll_loss=0.208958, article-summary:ntokens=4756.56, article-summary:nsentences=16, article-summary:sample_size=4756.56, gold_gen_byol:article:loss=0.0850007, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9707.09, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 040:    150 / 344 loss=2.244, nll_loss=0.209, ppl=1.16, wps=3078, ups=0, wpb=14153.450, bsz=48.000, num_updates=13548, lr=2.78442e-05, gnorm=0.771, clip=1.000, oom=0.000, loss_scale=0.500, wall=66647, train_wall=1.13834e+06, article-su      mmary:loss=2.15942, article-summary:nll_loss=0.209303, article-summary:ntokens=4686.7, article-summary:nsentences=16, article-summary:sample_size=4686.7, gold_gen_byol:article:loss=0.0850082, gold_gen_byol:article:nll_loss=0, gold_gen_byol:art      icle:ntokens=9466.75, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 040:    200 / 344 loss=2.244, nll_loss=0.209, ppl=1.16, wps=3072, ups=0, wpb=14046.592, bsz=48.000, num_updates=13598, lr=2.77916e-05, gnorm=1.026, clip=1.000, oom=0.000, loss_scale=0.500, wall=66872, train_wall=1.13856e+06, article-su      mmary:loss=2.15897, article-summary:nll_loss=0.20912, article-summary:ntokens=4669.78, article-summary:nsentences=16, article-summary:sample_size=4669.78, gold_gen_byol:article:loss=0.0848466, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9376.82, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 040:    250 / 344 loss=2.245, nll_loss=0.210, ppl=1.16, wps=3068, ups=0, wpb=13985.159, bsz=48.000, num_updates=13648, lr=2.77389e-05, gnorm=0.988, clip=1.000, oom=0.000, loss_scale=0.500, wall=67097, train_wall=1.13878e+06, article-su      mmary:loss=2.15996, article-summary:nll_loss=0.209872, article-summary:ntokens=4651.82, article-summary:nsentences=16, article-summary:sample_size=4651.82, gold_gen_byol:article:loss=0.084586, gold_gen_byol:article:nll_loss=0, gold_gen_byol:ar      ticle:ntokens=9333.34, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 040:    300 / 344 loss=2.244, nll_loss=0.210, ppl=1.16, wps=3089, ups=0, wpb=14112.522, bsz=48.000, num_updates=13698, lr=2.76863e-05, gnorm=0.947, clip=1.000, oom=0.000, loss_scale=0.500, wall=67328, train_wall=1.13902e+06, article-su      mmary:loss=2.16006, article-summary:nll_loss=0.210019, article-summary:ntokens=4691.46, article-summary:nsentences=16, article-summary:sample_size=4691.46, gold_gen_byol:article:loss=0.0843728, gold_gen_byol:article:nll_loss=0, gold_gen_byol:a      rticle:ntokens=9421.06, gold_gen_byol:article:nsentences=32, gold_gen_byol:article:sample_size=32
| epoch 040 | loss 2.244 | nll_loss 0.210 | ppl 1.16 | wps 3082 | ups 0 | wpb 14095.549 | bsz 47.962 | num_updates 13741 | lr 2.76411e-05 | gnorm 0.924 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 67526 | train_wall 1.13921e+06 | article      -summary:loss 2.16007 | article-summary:nll_loss 0.209986 | article-summary:ntokens 4679 | article-summary:nsentences 15.9855 | article-summary:sample_size 4679 | gold_gen_byol:article:loss 0.0842503 | gold_gen_byol:article:nll_loss 0 | gold_g      en_byol:article:ntokens 9416.55 | gold_gen_byol:article:nsentences 31.9767 | gold_gen_byol:article:sample_size 31.9767
| epoch 040 | valid on 'valid' subset | loss 3.965 | nll_loss 2.282 | ppl 4.86 | num_updates 13741 | best_loss 3.35637 | article-summary:loss 3.93686 | article-summary:nll_loss 2.25055 | article-summary:ntokens 1140.18 | article-summary:nsente      nces 3.98333 | article-summary:sample_size 1140.18
{   'accumulate_trans': None,
    'activation_dropout': 0.0,
    'activation_fn': 'gelu',
    'adam_betas': '(0.9, 0.999)',
    'adam_eps': 1e-08,
    'adaptive_input': False,
    'adaptive_softmax_cutoff': None,
    'adaptive_softmax_dropout': 0,
    'arch': 'backsum_transformer_bart_large',
    'article_downsampling': 'True',
    'attention_dropout': 0.1,
    'bart_mask_full_sent': 'False',
    'best_checkpoint_metric': 'loss',
    'bpe': None,
    'bt_beam_size': 1,
    'bucket_cap_mb': 25,
    'byol_ratio': '0',
    'change_langtok': False,
    'clip_norm': 0.1,
    'cpu': False,
    'criterion': 'label_smoothed_cross_entropy',
    'cross_byol': True,
    'cross_self_attention': False,
    'curriculum': 0,
    'data': 'data/cnn_dm-bin',
    'dataset_impl': None,
    'ddp_backend': 'no_c10d',
    'decoder_attention_heads': 16,
    'decoder_byol': '0',
    'decoder_embed_dim': 1024,
    'decoder_embed_path': None,
    'decoder_ffn_embed_dim': 4096,
    'decoder_input_dim': 1024,
    'decoder_layerdrop': 0,
    'decoder_layers': 12,
    'decoder_layers_to_keep': None,
    'decoder_learned_pos': True,
    'decoder_normalize_before': False,
    'decoder_output_dim': 1024,
    'device_id': 1,
    'disable_validation': False,
    'distributed_backend': 'nccl',
    'distributed_init_method': 'tcp://localhost:14848',
    'distributed_no_spawn': False,
    'distributed_port': -1,
    'distributed_rank': 1,
    'distributed_world_size': 4,
    'dropout': 0.1,
    'empty_cache_freq': 0,
    'encoder_attention_heads': 16,
    'encoder_embed_dim': 1024,
    'encoder_embed_path': None,
    'encoder_ffn_embed_dim': 4096,
    'encoder_layerdrop': 0,
    'encoder_layers': 12,
    'encoder_layers_to_keep': None,
    'encoder_learned_pos': True,
    'encoder_normalize_before': False,
    'end_learning_rate': 0.0,
    'fast_stat_sync': False,
    'find_unused_parameters': True,
    'fix_batches_to_gpus': False,
    'fixed_validation_seed': None,
    'force_anneal': None,
    'fp16': True,
    'fp16_init_scale': 128,
    'fp16_scale_tolerance': 0.0,
    'fp16_scale_window': None,
    'gen_sum_len': 140,
    'gold_gen_byol': '1',
    'init_from_pretrained_doc_model': True,
    'insert_sep': 'False',
    'keep_interval_updates': -1,
    'keep_last_epochs': -1,
    'label_smoothing': 0.1,
    'lambda_bart_pretrain_config': '0.0',
    'lambda_denoising_config': '0',
    'lambda_otf_bt_config': '0',
    'lambda_parallel_config': '1',
    'layer_wise_attention': False,
    'layernorm_embedding': True,
    'lazy_load': False,
    'left_pad_source': 'True',
    'left_pad_target': 'False',
    'load_decoders': True,
    'log_format': None,
    'log_interval': 50,
    'lr': [4e-05],
    'lr_scheduler': 'polynomial_decay',
    'max_epoch': 0,
    'max_sentences': 1,
    'max_sentences_valid': 1,
    'max_source_positions': 1024,
    'max_target_positions': 1024,
    'max_tokens': None,
    'max_tokens_valid': None,
    'max_update': 0,
    'max_word_shuffle_distance': 3.0,
    'maximize_best_checkpoint_metric': False,
    'memory_efficient_fp16': True,
    'min_loss_scale': 0.0001,
    'min_lr': -1,
    'momentum_contrast_beta': '0.99',
    'momentum_contrast_capcity': 10000,
    'momentum_contrast_loss_ratio': '0',
    'momentum_contrast_t': 1,
    'no_cross_attention': False,
    'no_epoch_checkpoints': True,
    'no_last_checkpoints': False,
    'no_progress_bar': False,
    'no_save': False,
    'no_save_optimizer_state': False,
    'no_scale_embedding': True,
    'no_token_positional_embeddings': False,
    'num_workers': 0,
    'optimizer': 'adam',
    'optimizer_overrides': '{}',
    'parallel_byol_ratio': '0',
    'pg_ratio': '0',
    'pooler_activation_fn': 'tanh',
    'pooler_dropout': 0.0,
    'power': 1.0,
    'pretrained_doc_model_path': '/data/xiehong/SeqCo/cnndm_bart/bart.large/model.pt',
    'raw_text': False,
    'relu_dropout': 0.0,
    'required_batch_size_multiple': 1,
    'reset_dataloader': False,
    'reset_lr_scheduler': False,
    'reset_meters': False,
    'reset_optimizer': False,
    'restore_file': 'checkpoint_last.pt',
    'save_dir': 'resutls/LE_sim_X,Y/cnndm_models/',
    'save_interval': 1,
    'save_interval_updates': 0,
    'seed': 1,
    'sentence_avg': False,
    'share_all_embeddings': True,
    'share_decoder_embeddings': False,
    'share_decoder_input_output_embed': True,
    'share_decoders': False,
    'share_encoder_embeddings': False,
    'share_encoders': True,
    'skip_invalid_size_inputs_valid_test': True,
    'source_lang': 'article',
    'summary_upsampling': 'True',
    'symmetrical': True,
    'target_lang': 'summary',
    'task': 'finetune_summarization',
    'tensorboard_logdir': '',
    'threshold_loss_scale': None,
    'tokenizer': None,
    'total_num_update': 40000,
    'train_subset': 'train',
    'truncate_source_positions': 1024,
    'two_side': False,
    'update_freq': [4],
    'upsample_primary': 1,
    'use_bmuf': False,
    'user_dir': None,
    'valid_subset': 'valid',
    'validate_interval': 1,
    'warmup_updates': 2000,
    'weight_decay': 0.01,
    'word_blanking_prob': 0.2,
    'word_dropout_prob': 0.1}
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
        add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
        add_(Tensor other, *, Number alpha)
/data/xiehong/anaconda3/envs/SeqCo/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
{   'accumulate_trans': None,
    'activation_dropout': 0.0,
    'activation_fn': 'gelu',
    'adam_betas': '(0.9, 0.999)',
    'adam_eps': 1e-08,
    'adaptive_input': False,
    'adaptive_softmax_cutoff': None,
    'adaptive_softmax_dropout': 0,
    'arch': 'backsum_transformer_bart_large',
    'article_downsampling': 'True',
    'attention_dropout': 0.1,
    'bart_mask_full_sent': 'False',
    'best_checkpoint_metric': 'loss',
    'bpe': None,
    'bt_beam_size': 1,
    'bucket_cap_mb': 25,
    'byol_ratio': '0',
    'change_langtok': False,
    'clip_norm': 0.1,
    'cpu': False,
    'criterion': 'label_smoothed_cross_entropy',
    'cross_byol': True,
    'cross_self_attention': False,
    'curriculum': 0,
    'data': 'data/cnn_dm-bin',
    'dataset_impl': None,
    'ddp_backend': 'no_c10d',
    'decoder_attention_heads': 16,
    'decoder_byol': '0',
    'decoder_embed_dim': 1024,
    'decoder_embed_path': None,
    'decoder_ffn_embed_dim': 4096,
    'decoder_input_dim': 1024,
    'decoder_layerdrop': 0,
    'decoder_layers': 12,
    'decoder_layers_to_keep': None,
    'decoder_learned_pos': True,
    'decoder_normalize_before': False,
    'decoder_output_dim': 1024,
    'device_id': 3,
    'disable_validation': False,
    'distributed_backend': 'nccl',
    'distributed_init_method': 'tcp://localhost:14848',
    'distributed_no_spawn': False,
    'distributed_port': -1,
    'distributed_rank': 3,
    'distributed_world_size': 4,
    'dropout': 0.1,
    'empty_cache_freq': 0,
    'encoder_attention_heads': 16,
    'encoder_embed_dim': 1024,
    'encoder_embed_path': None,
    'encoder_ffn_embed_dim': 4096,
    'encoder_layerdrop': 0,
    'encoder_layers': 12,
    'encoder_layers_to_keep': None,
    'encoder_learned_pos': True,
    'encoder_normalize_before': False,
    'end_learning_rate': 0.0,
    'fast_stat_sync': False,
    'find_unused_parameters': True,
    'fix_batches_to_gpus': False,
    'fixed_validation_seed': None,
    'force_anneal': None,
    'fp16': True,
    'fp16_init_scale': 128,
    'fp16_scale_tolerance': 0.0,
    'fp16_scale_window': None,
    'gen_sum_len': 140,
    'gold_gen_byol': '1',
    'init_from_pretrained_doc_model': True,
    'insert_sep': 'False',
    'keep_interval_updates': -1,
    'keep_last_epochs': -1,
    'label_smoothing': 0.1,
    'lambda_bart_pretrain_config': '0.0',
    'lambda_denoising_config': '0',
    'lambda_otf_bt_config': '0',
    'lambda_parallel_config': '1',
    'layer_wise_attention': False,
    'layernorm_embedding': True,
    'lazy_load': False,
    'left_pad_source': 'True',
    'left_pad_target': 'False',
    'load_decoders': True,
    'log_format': None,
    'log_interval': 50,
    'lr': [4e-05],
    'lr_scheduler': 'polynomial_decay',
    'max_epoch': 0,
    'max_sentences': 1,
    'max_sentences_valid': 1,
    'max_source_positions': 1024,
    'max_target_positions': 1024,
    'max_tokens': None,
    'max_tokens_valid': None,
    'max_update': 0,
    'max_word_shuffle_distance': 3.0,
    'maximize_best_checkpoint_metric': False,
    'memory_efficient_fp16': True,
    'min_loss_scale': 0.0001,
    'min_lr': -1,
    'momentum_contrast_beta': '0.99',
    'momentum_contrast_capcity': 10000,
    'momentum_contrast_loss_ratio': '0',
    'momentum_contrast_t': 1,
    'no_cross_attention': False,
    'no_epoch_checkpoints': True,
    'no_last_checkpoints': False,
    'no_progress_bar': False,
    'no_save': False,
    'no_save_optimizer_state': False,
    'no_scale_embedding': True,
    'no_token_positional_embeddings': False,
    'num_workers': 0,
    'optimizer': 'adam',
    'optimizer_overrides': '{}',
    'parallel_byol_ratio': '0',
    'pg_ratio': '0',
    'pooler_activation_fn': 'tanh',
    'pooler_dropout': 0.0,
    'power': 1.0,
    'pretrained_doc_model_path': '/data/xiehong/SeqCo/cnndm_bart/bart.large/model.pt',
    'raw_text': False,
    'relu_dropout': 0.0,
    'required_batch_size_multiple': 1,
    'reset_dataloader': False,
    'reset_lr_scheduler': False,
    'reset_meters': False,
    'reset_optimizer': False,
    'restore_file': 'checkpoint_last.pt',
    'save_dir': 'resutls/LE_sim_X,Y/cnndm_models/',
    'save_interval': 1,
    'save_interval_updates': 0,
    'seed': 1,
    'sentence_avg': False,
    'share_all_embeddings': True,
    'share_decoder_embeddings': False,
    'share_decoder_input_output_embed': True,
    'share_decoders': False,
    'share_encoder_embeddings': False,
    'share_encoders': True,
    'skip_invalid_size_inputs_valid_test': True,
    'source_lang': 'article',
    'summary_upsampling': 'True',
    'symmetrical': True,
    'target_lang': 'summary',
    'task': 'finetune_summarization',
    'tensorboard_logdir': '',
    'threshold_loss_scale': None,
    'tokenizer': None,
    'total_num_update': 40000,
    'train_subset': 'train',
    'truncate_source_positions': 1024,
    'two_side': False,
    'update_freq': [4],
    'upsample_primary': 1,
    'use_bmuf': False,
    'user_dir': None,
    'valid_subset': 'valid',
    'validate_interval': 1,
    'warmup_updates': 2000,
    'weight_decay': 0.01,
    'word_blanking_prob': 0.2,
    'word_dropout_prob': 0.1}
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
        add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
        add_(Tensor other, *, Number alpha)
/data/xiehong/anaconda3/envs/SeqCo/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
{   'accumulate_trans': None,
    'activation_dropout': 0.0,
    'activation_fn': 'gelu',
    'adam_betas': '(0.9, 0.999)',
    'adam_eps': 1e-08,
    'adaptive_input': False,
    'adaptive_softmax_cutoff': None,
    'adaptive_softmax_dropout': 0,
    'arch': 'backsum_transformer_bart_large',
    'article_downsampling': 'True',
    'attention_dropout': 0.1,
    'bart_mask_full_sent': 'False',
    'best_checkpoint_metric': 'loss',
    'bpe': None,
    'bt_beam_size': 1,
    'bucket_cap_mb': 25,
    'byol_ratio': '0',
    'change_langtok': False,
    'clip_norm': 0.1,
    'cpu': False,
    'criterion': 'label_smoothed_cross_entropy',
    'cross_byol': True,
    'cross_self_attention': False,
    'curriculum': 0,
    'data': 'data/cnn_dm-bin',
    'dataset_impl': None,
    'ddp_backend': 'no_c10d',
    'decoder_attention_heads': 16,
    'decoder_byol': '0',
    'decoder_embed_dim': 1024,
    'decoder_embed_path': None,
    'decoder_ffn_embed_dim': 4096,
    'decoder_input_dim': 1024,
    'decoder_layerdrop': 0,
    'decoder_layers': 12,
    'decoder_layers_to_keep': None,
    'decoder_learned_pos': True,
    'decoder_normalize_before': False,
    'decoder_output_dim': 1024,
    'device_id': 2,
    'disable_validation': False,
    'distributed_backend': 'nccl',
    'distributed_init_method': 'tcp://localhost:14848',
    'distributed_no_spawn': False,
    'distributed_port': -1,
    'distributed_rank': 2,
    'distributed_world_size': 4,
    'dropout': 0.1,
    'empty_cache_freq': 0,
    'encoder_attention_heads': 16,
    'encoder_embed_dim': 1024,
    'encoder_embed_path': None,
    'encoder_ffn_embed_dim': 4096,
    'encoder_layerdrop': 0,
    'encoder_layers': 12,
    'encoder_layers_to_keep': None,
    'encoder_learned_pos': True,
    'encoder_normalize_before': False,
    'end_learning_rate': 0.0,
    'fast_stat_sync': False,
    'find_unused_parameters': True,
    'fix_batches_to_gpus': False,
    'fixed_validation_seed': None,
    'force_anneal': None,
    'fp16': True,
    'fp16_init_scale': 128,
    'fp16_scale_tolerance': 0.0,
    'fp16_scale_window': None,
    'gen_sum_len': 140,
    'gold_gen_byol': '1',
    'init_from_pretrained_doc_model': True,
    'insert_sep': 'False',
    'keep_interval_updates': -1,
    'keep_last_epochs': -1,
    'label_smoothing': 0.1,
    'lambda_bart_pretrain_config': '0.0',
    'lambda_denoising_config': '0',
    'lambda_otf_bt_config': '0',
    'lambda_parallel_config': '1',
    'layer_wise_attention': False,
    'layernorm_embedding': True,
    'lazy_load': False,
    'left_pad_source': 'True',
    'left_pad_target': 'False',
    'load_decoders': True,
    'log_format': None,
    'log_interval': 50,
    'lr': [4e-05],
    'lr_scheduler': 'polynomial_decay',
    'max_epoch': 0,
    'max_sentences': 1,
    'max_sentences_valid': 1,
    'max_source_positions': 1024,
    'max_target_positions': 1024,
    'max_tokens': None,
    'max_tokens_valid': None,
    'max_update': 0,
    'max_word_shuffle_distance': 3.0,
    'maximize_best_checkpoint_metric': False,
    'memory_efficient_fp16': True,
    'min_loss_scale': 0.0001,
    'min_lr': -1,
    'momentum_contrast_beta': '0.99',
    'momentum_contrast_capcity': 10000,
    'momentum_contrast_loss_ratio': '0',
    'momentum_contrast_t': 1,
    'no_cross_attention': False,
    'no_epoch_checkpoints': True,
    'no_last_checkpoints': False,
    'no_progress_bar': False,
    'no_save': False,
    'no_save_optimizer_state': False,
    'no_scale_embedding': True,
    'no_token_positional_embeddings': False,
    'num_workers': 0,
    'optimizer': 'adam',
    'optimizer_overrides': '{}',
    'parallel_byol_ratio': '0',
    'pg_ratio': '0',
    'pooler_activation_fn': 'tanh',
    'pooler_dropout': 0.0,
    'power': 1.0,
    'pretrained_doc_model_path': '/data/xiehong/SeqCo/cnndm_bart/bart.large/model.pt',
    'raw_text': False,
    'relu_dropout': 0.0,
    'required_batch_size_multiple': 1,
    'reset_dataloader': False,
    'reset_lr_scheduler': False,
    'reset_meters': False,
    'reset_optimizer': False,
    'restore_file': 'checkpoint_last.pt',
    'save_dir': 'resutls/LE_sim_X,Y/cnndm_models/',
    'save_interval': 1,
    'save_interval_updates': 0,
    'seed': 1,
    'sentence_avg': False,
    'share_all_embeddings': True,
    'share_decoder_embeddings': False,
    'share_decoder_input_output_embed': True,
    'share_decoders': False,
    'share_encoder_embeddings': False,
    'share_encoders': True,
    'skip_invalid_size_inputs_valid_test': True,
    'source_lang': 'article',
    'summary_upsampling': 'True',
    'symmetrical': True,
    'target_lang': 'summary',
    'task': 'finetune_summarization',
    'tensorboard_logdir': '',
    'threshold_loss_scale': None,
    'tokenizer': None,
    'total_num_update': 40000,
    'train_subset': 'train',
    'truncate_source_positions': 1024,
    'two_side': False,
    'update_freq': [4],
    'upsample_primary': 1,
    'use_bmuf': False,
    'user_dir': None,
    'valid_subset': 'valid',
    'validate_interval': 1,
    'warmup_updates': 2000,
    'weight_decay': 0.01,
    'word_blanking_prob': 0.2,
    'word_dropout_prob': 0.1}
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
        add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
        add_(Tensor other, *, Number alpha)
/data/xiehong/anaconda3/envs/SeqCo/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
| saved checkpoint resutls/LE_sim_X,Y/cnndm_models/checkpoint_last.pt (epoch 40 @ 13741 updates) (writing took 8.370500802993774 seconds)
| done training in 67540.5 seconds
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
        add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
        add_(Tensor other, *, Number alpha)
/data/xiehong/anaconda3/envs/SeqCo/lib/python3.8/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
